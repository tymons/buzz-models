{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prepare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment prepares dataset containig normalized sound recordings extended with temperature and humidity values. For now we support only one hive for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1300001 - hive\n",
    "# 1300002 - not hive?\n",
    "# 1400001 - hive szymanski\n",
    "# 1400002 - hive szymanski\n",
    "#hives_ids = [1300001, 1300002, 1400001, 1400002]\n",
    "\n",
    "hives_ids = [1300001]\n",
    "DATA_INIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_INIT:\n",
    "    dfh_hives = [pd.read_csv(f\"measurements/{hive_id}/humidity.csv\") for hive_id in hives_ids]\n",
    "    dft_hives = [pd.read_csv(f\"measurements/{hive_id}/temperature.csv\") for hive_id in hives_ids]\n",
    "    dfh_hivesWithoutDuplicates = [dfh_hive.drop_duplicates(subset=['timestamp'], keep=False) for dfh_hive in dfh_hives]\n",
    "    dft_hivesWithoutDuplicates = [dft_hive.drop_duplicates(subset=['timestamp'], keep=False) for dft_hive in dft_hives]\n",
    "\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        print(f\"Hive no. {hives_ids[idx]} | humidity temperature dataset size : {dfh_hivesWithoutDuplicates[idx].shape} {dft_hivesWithoutDuplicates[idx].shape}\")\n",
    "\n",
    "    df_hive = [pd.merge(\n",
    "        dfh_hivesWithoutDuplicates[idx], dft_hivesWithoutDuplicates[idx], on='timestamp', suffixes=(f\"_humidity_{hive_id}\",f\"_temperature_{hive_id}\"))\n",
    "               for idx, hive_id in enumerate(hives_ids)]\n",
    "\n",
    "    \n",
    "    total = 0\n",
    "    for atmosphere_data in df_hive:\n",
    "        atmosphere_data['timestamp'] = pd.to_datetime(atmosphere_data['timestamp'], format='%Y-%m-%dT%H-%M-%S').sort_values()\n",
    "        atmosphere_data.set_index('timestamp', inplace=True)\n",
    "        print(f\"Atmospheric data after merge: {atmosphere_data.shape}\")\n",
    "        total += atmosphere_data.shape[0]\n",
    "    \n",
    "    print(f\"Total atmoshpere dataset size: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "if DATA_INIT:\n",
    "    hive_sounds = []\n",
    "    hive_timestamps = []\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        print(f\"Data preparation for hive: {hive_id}\")\n",
    "\n",
    "        sound_files = [f for f in glob.glob(f\"measurements\\\\{hive_id}\\\\sound*.csv\")]\n",
    "        sound_hive_list = []\n",
    "        for file in tqdm(sound_files):\n",
    "            df_samples = pd.read_csv(file)\n",
    "            pd_timestamp = pd.to_datetime(file.split(\"sound-\")[1].split(\".csv\")[0], format='%Y-%m-%dT%H-%M-%S')\n",
    "            if(len(df_samples.index) == 3000 and max(df_samples['samples'].values) < 4500):\n",
    "                np_samples = np.array(df_samples['samples'].values, dtype=\"float32\")\n",
    "                np_samples = np_samples / 4080\n",
    "                #np_samples = scaler.fit_transform(np_samples.reshape(-1, 1))\n",
    "                hive_sounds.append([pd_timestamp, np_samples])\n",
    "    sound_pd = pd.DataFrame(hive_sounds, columns=['timestamp', 'samples'])\n",
    "    sound_pd = sound_pd.set_index('timestamp')\n",
    "    \n",
    "    # Merge with atmosphere data\n",
    "    for index, row in sound_pd.iterrows():\n",
    "        atmosphere_nearest = atmosphere_data.iloc[atmosphere_data.index.get_loc(index, method='nearest')]\n",
    "        sound_pd.loc[index, 'humidity'] = atmosphere_nearest[f\"value_humidity_{hives_ids[0]}\"]\n",
    "        sound_pd.loc[index, 'temperature'] = atmosphere_nearest[f\"value_temperature_{hives_ids[0]}\"]\n",
    "    \n",
    "    np.save(f\"{hives_ids[0]}-data.npy\", sound_pd)\n",
    "    df_data = sound_pd\n",
    "else:\n",
    "    sound_pd = np.load(f\"{hives_ids[0]}-data.npy\", allow_pickle=True)\n",
    "    print(f\"Loaded dataset with size {len(hive_sounds)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block assumes that we have data in <code>df_data</code> variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "data_mfcc_labeled = []\n",
    "night_timestamps = df_data.between_time(\"23:00\", \"3:30\").index.values.tolist()\n",
    "night_timestamps = pd.to_datetime(night_timestamps)\n",
    "\n",
    "for index, row in tqdm(df_data.iterrows(), total=df_data.shape[0]):\n",
    "    full_mfccs = librosa.feature.mfcc(y=row['samples'], sr=3000, n_fft=512, hop_length=256, n_mfcc=14)\n",
    "    data_mfcc_labeled.append([np.mean(full_mfccs,axis=1), row['temperature'], row['humidity'],\n",
    "                              int(index in night_timestamps)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic classification PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "standarized_mfcc_avg = StandardScaler().fit_transform([data[0] for data in data_mfcc_labeled])\n",
    "standarized_temp = StandardScaler().fit_transform([[data[1]] for data in data_mfcc_labeled])\n",
    "standarized_hum = StandardScaler().fit_transform([[data[2]] for data in data_mfcc_labeled])\n",
    "\n",
    "zipped_data = list(zip(standarized_mfcc_avg, standarized_temp, standarized_hum))\n",
    "merged_data = [np.concatenate(list_to_con) for list_to_con in zipped_data]\n",
    "standarized_merged_data = StandardScaler().fit_transform(merged_data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pc_data = pca.fit_transform(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic classification t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2).fit_transform(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_data_labeled = list(zip(pc_data, [mfcc_data[3] for mfcc_data in data_mfcc_labeled]))\n",
    "colors = ['red', 'green', 'blue', 'yellow']\n",
    "labels = ['day', 'night']\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.scatter(x=[data[0][0] for data in pc_data_labeled],\n",
    "           y=[data[0][1] for data in pc_data_labeled],\n",
    "           c=[colors[int(data[1])] for data in pc_data_labeled],\n",
    "          alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.title(\"Mfcc scatter plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER - BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1300001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1664/1664 [00:02<00:00, 700.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1300002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1637/1637 [00:02<00:00, 685.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1400001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [00:01<00:00, 664.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1400002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 587/587 [00:00<00:00, 668.55it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_INIT = True\n",
    "import glob \n",
    "\n",
    "auto_hives = [1300001, 1300002, 1400001, 1400002]\n",
    "if DATA_INIT:\n",
    "    auto_max_sample_value = 0\n",
    "    auto_hive_sounds = []\n",
    "    auto_hive_timestamps = []\n",
    "    for idx, hive_id in enumerate(auto_hives):\n",
    "        print(f\"Data preparation for hive: {hive_id}\")\n",
    "\n",
    "        auto_sound_files = [f for f in glob.glob(f\"measurements\\\\{hive_id}\\\\sound*.csv\")]\n",
    "        auto_sound_hive_list = []\n",
    "        for file in tqdm(auto_sound_files):\n",
    "            df_samples = pd.read_csv(file)\n",
    "            pd_timestamp = pd.to_datetime(file.split(\"sound-\")[1].split(\".csv\")[0], format='%Y-%m-%dT%H-%M-%S')\n",
    "            if(len(df_samples.index) == 3000 and max(df_samples['samples'].values) < 4500):\n",
    "                np_samples = np.array(df_samples['samples'].values, dtype=\"float32\")\n",
    "                np_samples = np_samples / 4080\n",
    "                auto_hive_sounds.append([pd_timestamp, np_samples])\n",
    "    np.random.shuffle(auto_hive_sounds)\n",
    "    sound_pd = pd.DataFrame(auto_hive_sounds, columns=['timestamp', 'samples'])\n",
    "    auto_df_data = sound_pd.set_index('timestamp')\n",
    "    auto_df_data = sound_pd\n",
    "else:\n",
    "    sound_pd = np.load(f\"{hives_ids[0]}-data.npy\", allow_pickle=True)\n",
    "    print(f\"Loaded dataset with size {len(hive_sounds)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-4\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3000, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 256))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(2048, 3000), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data = torch.Tensor([auto_df_data['samples'].values])\n",
    "index = round(0.3 * tensor_data.size()[1])\n",
    "trainset = torch.utils.data.DataLoader(tensor_data[:, :-index, :], batch_size=20, shuffle=True)\n",
    "test_data = torch.utils.data.DataLoader(tensor_data[:, -index:, :], batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in tqdm(sound_trainset):\n",
    "        X, y = data\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f\"epoch [{epoch}/{num_epochs}], loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'autoencoder-basic-model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('autoencoder-basic-model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in tqdm(sound_trainset):\n",
    "        X, y = data\n",
    "        output = model(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
