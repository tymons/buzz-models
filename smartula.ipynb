{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atmospheric Data - preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hives_ids = [1300001, 1300002, 1400001, 1400002]\n",
    "DATA_INIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hive no. 1300001 | humidity temperature dataset size : (6776, 2) (6786, 2)\n",
      "Hive no. 1300002 | humidity temperature dataset size : (6865, 2) (6867, 2)\n",
      "Hive no. 1400001 | humidity temperature dataset size : (2444, 2) (2457, 2)\n",
      "Hive no. 1400002 | humidity temperature dataset size : (1948, 2) (1949, 2)\n",
      "Atmospheric data after merge: (6696, 2)\n",
      "Atmospheric data after merge: (6778, 2)\n",
      "Atmospheric data after merge: (2418, 2)\n",
      "Atmospheric data after merge: (1936, 2)\n",
      "Total atmoshpere dataset size: 17828\n"
     ]
    }
   ],
   "source": [
    "if DATA_INIT:\n",
    "    dfh_hives = [pd.read_csv(f\"measurements/{hive_id}/humidity.csv\") for hive_id in hives_ids]\n",
    "    dft_hives = [pd.read_csv(f\"measurements/{hive_id}/temperature.csv\") for hive_id in hives_ids]\n",
    "    dfh_hivesWithoutDuplicates = [dfh_hive.drop_duplicates(subset=['timestamp'], keep=False) for dfh_hive in dfh_hives]\n",
    "    dft_hivesWithoutDuplicates = [dft_hive.drop_duplicates(subset=['timestamp'], keep=False) for dft_hive in dft_hives]\n",
    "\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        print(f\"Hive no. {hives_ids[idx]} | humidity temperature dataset size : {dfh_hivesWithoutDuplicates[idx].shape} {dft_hivesWithoutDuplicates[idx].shape}\")\n",
    "\n",
    "    df_hive = [pd.merge(\n",
    "        dfh_hivesWithoutDuplicates[idx], dft_hivesWithoutDuplicates[idx], on='timestamp', suffixes=(f\"_humidity_{hive_id}\",f\"_temperature_{hive_id}\"))\n",
    "               for idx, hive_id in enumerate(hives_ids)]\n",
    "\n",
    "    \n",
    "    total = 0\n",
    "    for atmosphere_data in df_hive:\n",
    "        atmosphere_data['timestamp'] = pd.to_datetime(atmosphere_data['timestamp'], format='%Y-%m-%dT%H-%M-%S').sort_values()\n",
    "        atmosphere_data.set_index('timestamp', inplace=True)\n",
    "        print(f\"Atmospheric data after merge: {atmosphere_data.shape}\")\n",
    "        total += atmosphere_data.shape[0]\n",
    "    \n",
    "    print(f\"Total atmoshpere dataset size: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound Data - preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1300001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1664/1664 [00:13<00:00, 126.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1300002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1637/1637 [00:13<00:00, 125.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1400001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [00:06<00:00, 112.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation for hive: 1400002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 587/587 [00:05<00:00, 102.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of hive sound data: 4529, with max value: 4080.0\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "if DATA_INIT:\n",
    "    hive_sounds = []\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        print(f\"Data preparation for hive: {hive_id}\")\n",
    "\n",
    "        sound_files = [f for f in glob.glob(f\"measurements\\\\{hive_id}\\\\sound*.csv\")]\n",
    "        sound_hive_list = []\n",
    "        for file in tqdm(sound_files):\n",
    "            df_samples = pd.read_csv(file)\n",
    "            pd_timestamp = pd.to_datetime(file.split(\"sound-\")[1].split(\".csv\")[0], format='%Y-%m-%dT%H-%M-%S')\n",
    "            if(len(df_samples.index) == 3000 and max(df_samples['samples'].values) < 4500):\n",
    "                np_samples = np.array(df_samples['samples'].values, dtype=\"float32\")\n",
    "                #np_samples = scaler.fit_transform(np_samples.reshape(-1, 1))\n",
    "                hive_sounds.append([pd_timestamp, np_samples, np.eye(len(hives_ids))[idx]])\n",
    "    \n",
    "    # Normalize in place\n",
    "    max_value = reduce(max, map(lambda x:max(x[1]), hive_sounds))\n",
    "    for sound in hive_sounds:\n",
    "        sound[1] = np.true_divide(sound[1], max_value)\n",
    "        \n",
    "    print(f\"Size of hive sound data: {len(hive_sounds)}, with max value: {max_value}\")\n",
    "    np.random.shuffle(hive_sounds)\n",
    "    np.save(\"sound_data_training.npy\", hive_sounds)\n",
    "    data = hive_sounds\n",
    "else:\n",
    "    data = np.load(\"sound_data_training.npy\", allow_pickle=True)\n",
    "    print(f\"Loaded: {len(hive_sounds)} sound recordings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER - BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-4\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3000, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 256))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(2048, 3000), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "\n",
    "sound_dataset = utils.TensorDataset(torch.Tensor([x[0] for x in training_data_sound]),\n",
    "                                   torch.Tensor([x[1] for x in training_data_sound])) # create your datset\n",
    "                                    \n",
    "print(\"Length of complete sound dataset is\", len(sound_dataset))\n",
    "sound_trainset = torch.utils.data.DataLoader(sound_dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in tqdm(sound_trainset):\n",
    "        X, y = data\n",
    "        model.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print(f\"epoch [{epoch}/{num_epochs}], loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'autoencoder-basic-model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('autoencoder-basic-model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in tqdm(sound_trainset):\n",
    "        X, y = data\n",
    "        output = model(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,7,8,98,90,0]\n",
    "print(a[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=20, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def weight_reset(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.reset_parameters()\n",
    "        \n",
    "        \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "EPOCHS = 6\n",
    "\n",
    "net.weight_reset()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 784))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Current loss is: \", loss.item())\n",
    "    if loss < 1e-5:\n",
    "        print(\"Loss threshold obtained!\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy on test data: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy on train data: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartula-core",
   "language": "python",
   "name": "smartula-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
