{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import glob\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.layers import (Input, Dense)\n",
    "from smartula_analyze import save_to_file, is_affected\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to tuple list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with: C:\\Users\\tymons\\001.Projects\\003.eul\\workspace\\smartula-analysis\\core\\csv\\2019-06-06T03-23-11.csv. Got length:1000\n",
      "Error with: C:\\Users\\tymons\\001.Projects\\003.eul\\workspace\\smartula-analysis\\core\\csv\\2019-06-07T03-09-11.csv. Got length:1000\n"
     ]
    }
   ],
   "source": [
    "audio_len = 1500\n",
    "\n",
    "if os.name == \"nt\":\n",
    "    path_name = \"C:\\\\Users\\\\tymons\\\\001.Projects\\\\003.eul\\\\workspace\\\\smartula-analysis\\\\core\\\\csv\\\\\"\n",
    "else:\n",
    "    path_name = \"/home/tymons/Projects/003.eul/workspace/smartula-analysis/csv/\"\n",
    "    \n",
    "\n",
    "all_filenames = [i for i in glob.glob(f\"{path_name}*.csv\")]\n",
    "#all_filenames = all_filenames[:2]\n",
    "\n",
    "list_of_audios = []\n",
    "for filename in all_filenames:\n",
    "    samples = pd.read_csv(filename, header=None).values[:audio_len].astype(float)\n",
    "    samples = samples - samples.mean()\n",
    "    samples = samples.reshape(samples.size)\n",
    "    timestamp = filename.split(os.sep)[-1].split(\".\")[0]\n",
    "    \n",
    "    dict_sm = {\"timestamp\" : timestamp,\n",
    "               \"samples\" : samples,\n",
    "               \"class\" : is_affected(timestamp, [(\"2019-06-04T18-22-00\", \"2019-06-04T20-30-00\"),\n",
    "                                                (\"2019-06-05T20-46-00\", \"2019-06-05T23-48-00\"),\n",
    "                                                (\"2019-06-06T22-23-00\", \"2019-06-07T05-52-00\")])}\n",
    "           \n",
    "    if len(samples) == audio_len:\n",
    "        list_of_audios.append(dict_sm)\n",
    "    else:\n",
    "        print(\"Error with: \" + filename +\". Got length:\" + str(samples.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tymons\\001.Projects\\003.eul\\workspace\\smartula-analysis\\core\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "encoding_dim = 32 \n",
    "\n",
    "sound_input = Input(shape=(1500,))\n",
    "encoded = Dense(784, activation='relu')(sound_input)\n",
    "encoded = Dense(128, activation='relu')(encoded)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "latent = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(latent)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='relu')(decoded)\n",
    "decoded = Dense(1500, activation='sigmoid')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(sound_input, decoded)\n",
    "encoder = Model(sound_input, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Standarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.8\n",
    "\n",
    "data = np.array([audio[\"samples\"] for audio in list_of_audios])\n",
    "data = preprocessing.scale(data)\n",
    "data = preprocessing.normalize(data)\n",
    "\n",
    "index = int(k*len(data))\n",
    "x_train = data[:index]\n",
    "x_test = data[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tymons\\001.Projects\\003.eul\\workspace\\smartula-analysis\\core\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 855 samples, validate on 214 samples\n",
      "Epoch 1/500\n",
      "855/855 [==============================] - 2s 2ms/step - loss: 0.2498 - val_loss: 0.2500\n",
      "Epoch 2/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2493 - val_loss: 0.2495\n",
      "Epoch 3/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2488 - val_loss: 0.2490\n",
      "Epoch 4/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2482 - val_loss: 0.2484\n",
      "Epoch 5/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2477 - val_loss: 0.2479\n",
      "Epoch 6/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2472 - val_loss: 0.2473\n",
      "Epoch 7/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2466 - val_loss: 0.2468\n",
      "Epoch 8/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2460 - val_loss: 0.2462\n",
      "Epoch 9/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2454 - val_loss: 0.2455\n",
      "Epoch 10/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2448 - val_loss: 0.2449\n",
      "Epoch 11/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2441 - val_loss: 0.2441\n",
      "Epoch 12/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2433 - val_loss: 0.2433\n",
      "Epoch 13/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2425 - val_loss: 0.2424\n",
      "Epoch 14/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2415 - val_loss: 0.2414\n",
      "Epoch 15/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2404 - val_loss: 0.2402\n",
      "Epoch 16/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2391 - val_loss: 0.2387\n",
      "Epoch 17/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2375 - val_loss: 0.2368\n",
      "Epoch 18/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2353 - val_loss: 0.2342\n",
      "Epoch 19/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2322 - val_loss: 0.2303\n",
      "Epoch 20/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2273 - val_loss: 0.2235\n",
      "Epoch 21/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.2180 - val_loss: 0.2089\n",
      "Epoch 22/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.1944 - val_loss: 0.1646\n",
      "Epoch 23/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.1180 - val_loss: 0.0467\n",
      "Epoch 24/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.0209 - val_loss: 0.0055\n",
      "Epoch 25/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 26/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 27/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 28/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 29/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 9.6047e-04 - val_loss: 9.3712e-04\n",
      "Epoch 30/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 8.9310e-04 - val_loss: 8.8240e-04\n",
      "Epoch 31/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 8.4832e-04 - val_loss: 8.4431e-04\n",
      "Epoch 32/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 8.1663e-04 - val_loss: 8.1654e-04\n",
      "Epoch 33/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.9324e-04 - val_loss: 7.9545e-04\n",
      "Epoch 34/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.7532e-04 - val_loss: 7.7898e-04\n",
      "Epoch 35/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.6124e-04 - val_loss: 7.6584e-04\n",
      "Epoch 36/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.4996e-04 - val_loss: 7.5516e-04\n",
      "Epoch 37/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.4075e-04 - val_loss: 7.4632e-04\n",
      "Epoch 38/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.3312e-04 - val_loss: 7.3892e-04\n",
      "Epoch 39/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.2672e-04 - val_loss: 7.3267e-04\n",
      "Epoch 40/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.2130e-04 - val_loss: 7.2731e-04\n",
      "Epoch 41/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.1665e-04 - val_loss: 7.2269e-04\n",
      "Epoch 42/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.1264e-04 - val_loss: 7.1867e-04\n",
      "Epoch 43/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.0915e-04 - val_loss: 7.1515e-04\n",
      "Epoch 44/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.0609e-04 - val_loss: 7.1203e-04\n",
      "Epoch 45/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.0338e-04 - val_loss: 7.0926e-04\n",
      "Epoch 46/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 7.0098e-04 - val_loss: 7.0679e-04\n",
      "Epoch 47/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.9883e-04 - val_loss: 7.0457e-04\n",
      "Epoch 48/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.9690e-04 - val_loss: 7.0256e-04\n",
      "Epoch 49/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.9516e-04 - val_loss: 7.0074e-04\n",
      "Epoch 50/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.9358e-04 - val_loss: 6.9909e-04\n",
      "Epoch 51/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.9215e-04 - val_loss: 6.9758e-04\n",
      "Epoch 52/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.9084e-04 - val_loss: 6.9619e-04\n",
      "Epoch 53/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8964e-04 - val_loss: 6.9491e-04\n",
      "Epoch 54/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8853e-04 - val_loss: 6.9374e-04\n",
      "Epoch 55/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8752e-04 - val_loss: 6.9265e-04\n",
      "Epoch 56/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8658e-04 - val_loss: 6.9164e-04\n",
      "Epoch 57/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8571e-04 - val_loss: 6.9070e-04\n",
      "Epoch 58/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8490e-04 - val_loss: 6.8983e-04\n",
      "Epoch 59/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8415e-04 - val_loss: 6.8901e-04\n",
      "Epoch 60/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8344e-04 - val_loss: 6.8824e-04\n",
      "Epoch 61/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8279e-04 - val_loss: 6.8753e-04\n",
      "Epoch 62/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8217e-04 - val_loss: 6.8685e-04\n",
      "Epoch 63/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8160e-04 - val_loss: 6.8622e-04\n",
      "Epoch 64/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8105e-04 - val_loss: 6.8562e-04\n",
      "Epoch 65/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8054e-04 - val_loss: 6.8506e-04\n",
      "Epoch 66/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.8006e-04 - val_loss: 6.8453e-04\n",
      "Epoch 67/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7961e-04 - val_loss: 6.8402e-04\n",
      "Epoch 68/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7918e-04 - val_loss: 6.8354e-04\n",
      "Epoch 69/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7877e-04 - val_loss: 6.8309e-04\n",
      "Epoch 70/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7838e-04 - val_loss: 6.8266e-04\n",
      "Epoch 71/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7802e-04 - val_loss: 6.8224e-04\n",
      "Epoch 72/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7767e-04 - val_loss: 6.8185e-04\n",
      "Epoch 73/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7734e-04 - val_loss: 6.8148e-04\n",
      "Epoch 74/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7702e-04 - val_loss: 6.8112e-04\n",
      "Epoch 75/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7672e-04 - val_loss: 6.8078e-04\n",
      "Epoch 76/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7643e-04 - val_loss: 6.8046e-04\n",
      "Epoch 77/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7616e-04 - val_loss: 6.8014e-04\n",
      "Epoch 78/500\n",
      "855/855 [==============================] - 1s 1ms/step - loss: 6.7590e-04 - val_loss: 6.7985e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ca3f8a3400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = [EarlyStopping(monitor='val_loss', min_delta=1e-06, patience=3)]\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=500,\n",
    "                shuffle=True,\n",
    "                batch_size = 100,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks = es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_samples = np.array([audio_dict['samples'] for audio_dict in list_of_audios])\n",
    "predictions = encoder.predict(list_of_samples)\n",
    "classes = [audio_dict['class'] for audio_dict in list_of_audios]\n",
    "colors = [\"red\" if category else \"green\" for category in classes]\n",
    "pred_class_col = list(zip(predictions, classes, colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 16 nearest neighbors...\n",
      "[t-SNE] Indexed 1069 samples in 0.002s...\n",
      "[t-SNE] Computed neighbors for 1069 samples in 0.042s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1069\n",
      "[t-SNE] Computed conditional probabilities for sample 1069 / 1069\n",
      "[t-SNE] Mean sigma: 27.492443\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 79.645157\n",
      "[t-SNE] KL divergence after 2500 iterations: 1.065493\n"
     ]
    }
   ],
   "source": [
    "features_embedded = TSNE(n_components=2, perplexity=5, learning_rate=500, n_iter=2500, verbose=1) \\\n",
    "       .fit_transform([elem[0] for elem in pred_class_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "features_embedded = pca.fit_transform([elem[0] for elem in pred_class_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_class_col = list(zip(features_embedded, classes, colors, [audio[\"timestamp\"] for audio in list_of_audios]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# # Create plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for data, group, color, timestamp in features_class_col:\n",
    "    x, y = data\n",
    "    ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=30, label=str(group))\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "data_frame = pd.DataFrame()\n",
    "\n",
    "np_features_class_col_t = np.asarray(features_class_col)\n",
    "\n",
    "data_frame['colors'] = [\"#003399\" if group == True else \"#ff0000\" for group in np_features_class_col_t[:, 1]]\n",
    "data_frame['timestamp'] = np_features_class_col_t[:, 3]\n",
    "data_frame['group'] = np_features_class_col_t[:, 1]\n",
    "data_frame['x'] = [point[0] for point in np_features_class_col_t[:, 0]]\n",
    "data_frame['y'] = [point[1] for point in np_features_class_col_t[:, 0]]\n",
    "\n",
    "source = ColumnDataSource(data=data_frame)\n",
    "\n",
    "tools = \"hover,pan,wheel_zoom,zoom_in,zoom_out,box_zoom,undo,redo,reset,tap,save,box_select,\" \\\n",
    "        \"poly_select,lasso_select, \"\n",
    "tooltips = [\n",
    "    (\"timestamp\", \"@timestamp\"),\n",
    "    (\"class\", \"@group\")\n",
    "]\n",
    "p = figure(tools=tools, tooltips=tooltips)\n",
    "p.scatter(x='x', y='y', fill_color='colors', fill_alpha=0.4, source=source, size=15, line_color=None)\n",
    "output_file(\"color_scatter.html\", title=\"color_scatter.py example\")\n",
    "show(p)  # open a browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features_class_col_t[:2, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartula-core",
   "language": "python",
   "name": "smartula-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
