{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "hives_ids = [\"smrpiclient7\", \"smrpiclient6\", \"smrpiclient5\"]\n",
    "# hives_ids = [\"smrpiclient7\"]\n",
    "\n",
    "# define hive under analysis\n",
    "hive_under_analysis = hives_ids[0]\n",
    "# define offset as all data should be utc\n",
    "timezone_offset_hours = 2\n",
    "# define if we should reinit our data\n",
    "DATA_INIT = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.periodogram_dataset_keras' from 'C:\\\\Users\\\\tymot\\\\projects\\\\001.smartula\\\\smartula-analysis\\\\smartula-analysis\\\\notebooks\\\\utils\\\\periodogram_dataset_keras.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.periodogram_dataset as pd\n",
    "import utils.periodogram_dataset_keras as pdk\n",
    "import utils.contrastive_pytorch as cp\n",
    "import utils.contrastive_keras as ck\n",
    "import utils.data_utils as du\n",
    "import importlib\n",
    "\n",
    "importlib.reload(ck)\n",
    "importlib.reload(pdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data and remove these with invalid RMS. Save filenames to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 35899 files for ['smrpiclient7', 'smrpiclient6', 'smrpiclient5']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "CHECK_FILES = False\n",
    "\n",
    "if CHECK_FILES:\n",
    "    folders = [folder for folder in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\smrpiclient*_*\\\\\")]\n",
    "    for folder in folders:\n",
    "        print(f\"checking folder {folder.split(os.sep)[-2]}\", flush=True)\n",
    "        files = [file for file in glob.glob(f\"{folder}*.wav\")]\n",
    "        valid_files = []\n",
    "        for filename in tqdm(files):\n",
    "            # check filename and write its filename to list if is valid\n",
    "            sample_rate, sound_samples = wavfile.read(filename)\n",
    "            if len(sound_samples.shape) > 1:\n",
    "                sound_samples = sound_samples.T[0]\n",
    "            sound_samples = sound_samples/(2.0**31)\n",
    "            rms = math.sqrt(sum(sound_samples**2)/len(sound_samples))\n",
    "            if rms < 0.8:\n",
    "                valid_files.append(filename)\n",
    "        \n",
    "        with open(f'{folder}valid-files.txt', 'w') as f:\n",
    "            f.write(\"\\n\".join(valid_files))\n",
    "else:\n",
    "    # read files\n",
    "    valid_files = []\n",
    "    summary_files = [f for hive_name in hives_ids for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name}_*\\\\valid-files.txt\")]\n",
    "    for summary_file in summary_files:\n",
    "        with open(summary_file, 'r') as f:\n",
    "            valid_files += f.read().splitlines()\n",
    "    print(f'got {len(valid_files)} files for {str(hives_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing train dataset with len: 35899\n",
      "VAE model training performed on cuda\n",
      "-> training at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [00:20<00:00, 19.16it/s]\n",
      "100%|██████████| 393/393 [00:20<00:00, 19.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.98it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] train_loss: 974.68406 valid_loss: 330.78709 checkpoint!\n",
      "-> training at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.84it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.78it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] train_loss: 327.11547 valid_loss: 328.08288 checkpoint!\n",
      "-> training at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.28it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.19it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/10] train_loss: 325.35126 valid_loss: 325.98288 checkpoint!\n",
      "-> training at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.20it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.13it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/10] train_loss: 323.75697 valid_loss: 323.39692 checkpoint!\n",
      "-> training at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 23.03it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.50it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/10] train_loss: 322.86905 valid_loss: 323.06929 checkpoint!\n",
      "-> training at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:19<00:00, 20.03it/s]\n",
      "100%|██████████| 393/393 [00:19<00:00, 20.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.00it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 21.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/10] train_loss: 322.20532 valid_loss: 323.29224 .\n",
      "-> training at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.88it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 23.06it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 23.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/10] train_loss: 321.38089 valid_loss: 318.83929 checkpoint!\n",
      "-> training at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:18<00:00, 20.92it/s]\n",
      "100%|██████████| 393/393 [00:18<00:00, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.20it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/10] train_loss: 317.34038 valid_loss: 314.84466 checkpoint!\n",
      "-> training at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.93it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.97it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/10] train_loss: 312.25993 valid_loss: 314.73113 checkpoint!\n",
      "-> training at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.78it/s]\n",
      "100%|██████████| 393/393 [00:17<00:00, 22.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.17it/s]\n",
      "100%|██████████| 393/393 [00:16<00:00, 23.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] train_loss: 310.33000 valid_loss: 307.92804 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.periodogram_dataset import PeriodogramDataset\n",
    "from utils.contrastive_pytorch import VAE, train_vae_model\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'models\\\\vae-apprirary-approach-05022021.pth'\n",
    "TRAIN = True\n",
    "\n",
    "modelVAE = VAE(encoder_layer_sizes=[2048, 512, 64], latent_size=16, decoder_layer_sizes=[64, 512, 2048]).to(device)\n",
    "\n",
    "if TRAIN:\n",
    "    sound_files = valid_files\n",
    "    test_size = 0.15\n",
    "    val_size = 0.15\n",
    "\n",
    "    print(f\"preparing train dataset with len: {len(sound_files)}\")\n",
    "    dataset = PeriodogramDataset(sound_files, hives_ids, slice_freq=(0, 2048))\n",
    "    test_amount, val_amount = int(dataset.__len__() * test_size), int(dataset.__len__() * val_size)\n",
    "    train_set, val_set, test_set = random_split(dataset,\n",
    "                                                [(dataset.__len__() - (test_amount + val_amount)), \n",
    "                                                 test_amount, val_amount])\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "    modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=100,\n",
    "                                  dataloader_train=train_loader, dataloader_val=val_loader, checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelVAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>/<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "target = train_data[0]\n",
    "background = train_data[1]\n",
    "print(f'{type(target[0])}/{type(background)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "386/386 [==============================] - 51s 132ms/step - loss: 11.2057\n",
      "Epoch 2/20\n",
      "386/386 [==============================] - 46s 119ms/step - loss: 9.5479\n",
      "Epoch 3/20\n",
      "386/386 [==============================] - 45s 118ms/step - loss: 9.2809\n",
      "Epoch 4/20\n",
      "386/386 [==============================] - 46s 118ms/step - loss: 9.0541\n",
      "Epoch 5/20\n",
      "386/386 [==============================] - 47s 121ms/step - loss: 8.8734\n",
      "Epoch 6/20\n",
      "386/386 [==============================] - 46s 119ms/step - loss: 8.7631\n",
      "Epoch 7/20\n",
      "386/386 [==============================] - 48s 123ms/step - loss: 8.6722\n",
      "Epoch 8/20\n",
      "386/386 [==============================] - 47s 121ms/step - loss: 8.6254\n",
      "Epoch 9/20\n",
      "386/386 [==============================] - 46s 120ms/step - loss: 8.5728\n",
      "Epoch 10/20\n",
      "386/386 [==============================] - 46s 120ms/step - loss: 8.5581\n",
      "Epoch 11/20\n",
      "386/386 [==============================] - 47s 122ms/step - loss: 8.5170\n",
      "Epoch 12/20\n",
      "386/386 [==============================] - 48s 123ms/step - loss: 8.4914\n",
      "Epoch 13/20\n",
      "386/386 [==============================] - 47s 123ms/step - loss: 8.4646\n",
      "Epoch 14/20\n",
      "386/386 [==============================] - 46s 120ms/step - loss: 8.4712\n",
      "Epoch 15/20\n",
      "386/386 [==============================] - 46s 120ms/step - loss: 8.4592\n",
      "Epoch 16/20\n",
      "386/386 [==============================] - 49s 126ms/step - loss: 8.4260\n",
      "Epoch 17/20\n",
      "386/386 [==============================] - 58s 149ms/step - loss: 8.4296\n",
      "Epoch 18/20\n",
      "386/386 [==============================] - 47s 122ms/step - loss: 8.4361\n",
      "Epoch 19/20\n",
      "386/386 [==============================] - 47s 121ms/step - loss: 8.4105\n",
      "Epoch 20/20\n",
      "386/386 [==============================] - 48s 124ms/step - loss: 8.3841\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "from utils.periodogram_dataset_keras import PeriodogramGenerator\n",
    "from utils.contrastive_keras import contrastive_keras_vae\n",
    "\n",
    "bsize = 32\n",
    "\n",
    "target_hive = \"smrpiclient6\"\n",
    "target_valid_file = glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{target_hive}_*\\\\valid-files.txt\")\n",
    "target_valid_filenames = []\n",
    "with open(target_valid_file[0], 'r') as f:\n",
    "    target_valid_filenames = f.read().splitlines()\n",
    "    \n",
    "background_hives = [\"smrpiclient5\", \"smrpiclient7\"]\n",
    "background_valid_files = [f for background_hive in background_hives for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{background_hive}_*\\\\valid-files.txt\")]\n",
    "background_valid_filenames = []\n",
    "for background_valid_file in background_valid_files:\n",
    "    with open(background_valid_file, 'r') as f:\n",
    "        background_valid_filenames += f.read().splitlines()\n",
    "        \n",
    "background_valid_filenames = background_valid_filenames[:len(target_valid_filenames)]\n",
    "        \n",
    "train_generator = PeriodogramGenerator(target_valid_filenames, background_valid_filenames,\n",
    "                                       batch_size=bsize, labels=[target_hive], slice_freq=(0, 2048))\n",
    "\n",
    "cvae_keras, _, _, _, sb_encoder, cvae_decoder = contrastive_keras_vae(input_dim=2048, intermediate_dim=[512, 64], latent_dim=16,\n",
    "                                               disentangle=True, gamma=1, batch_size=bsize)\n",
    "\n",
    "history = cvae_keras.fit(train_generator, epochs=20, batch_size=bsize, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:08<00:00, 283.85it/s]\n",
      "  3%|▎         | 75/2452 [00:00<00:06, 373.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:06<00:00, 364.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss vs train loss : 9.49 : 5.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.periodogram_dataset import PeriodogramDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data_utils import normal_pdf\n",
    "\n",
    "hives_ids_test = [\"smrpiclient3\"]\n",
    "hut_sounds_files = [f for hive_name_test in hives_ids_test for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name_test}_*\\\\*.wav\")]\n",
    "all_sound_files = [f for hive_name in hives_ids for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name}_*\\\\*.wav\")]\n",
    "\n",
    "# pytorch\n",
    "hut_dataset = PeriodogramDataset(hut_sounds_files, hives_ids_test, slice_freq=(0, 2048))\n",
    "all_sound_dataset = PeriodogramDataset(all_sound_files, hives_ids, slice_freq=(0, 2048))\n",
    "\n",
    "# get indices for all_sound_dataset\n",
    "subset_indices = np.random.randint(0, len(all_sound_dataset), len(hut_dataset))\n",
    "dataset = torch.utils.data.Subset(all_sound_dataset, subset_indices)\n",
    "\n",
    "test_loss = []\n",
    "train_loss = []\n",
    "with torch.no_grad():\n",
    "    modelVAE.eval()\n",
    "    print(f'validating on test set', flush=True)\n",
    "    for input_data in tqdm(hut_dataset, position=0, leave=True):\n",
    "        if input_data:\n",
    "            input_data = torch.Tensor(input_data[0]).to(device)\n",
    "            output, mean, var = modelVAE(input_data.to(device))\n",
    "            test_loss.append(F.mse_loss(output, input_data, reduction='sum').cpu().numpy())\n",
    "            \n",
    "    print(f'validating on training set')\n",
    "    for input_data in tqdm(dataset, position=0, leave=True):\n",
    "        if input_data:\n",
    "            input_data = torch.Tensor(input_data[0]).to(device)\n",
    "            output, _, _ = modelVAE(input_data.to(device))\n",
    "            train_loss.append(F.mse_loss(output, input_data, reduction='sum').cpu().numpy())\n",
    "                \n",
    "test_loss_avg = np.mean(test_loss)\n",
    "train_loss_avg = np.mean(train_loss)\n",
    "                                       \n",
    "print(f'test loss vs train loss : {test_loss_avg:.2f} : {train_loss_avg:.2f}')\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:04<00:00, 514.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from operator import itemgetter \n",
    "from utils.periodogram_dataset_keras import PeriodogramGenerator, read_sound_file\n",
    "from tqdm import tqdm \n",
    "\n",
    "hut_sounds =  np.array([read_sound_file(f, (0, 2048)) for f in tqdm(hut_sounds_files)])\n",
    "mean, var, latent = sb_encoder.predict(hut_sounds)\n",
    "zeros = np.zeros_like(latent)\n",
    "decoder_input = np.concatenate((zeros, latent), axis=1)\n",
    "cvae_output = cvae_decoder.predict(decoder_input)\n",
    "loss = tf.keras.losses.mean_squared_error(hut_sounds, cvae_output)\n",
    "\n",
    "print(f'MSE loss for hive under test: {np.mean(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indices = np.random.randint(0, len(background_valid_filenames), len(hut_sounds))\n",
    "\n",
    "background_train_sound_files = list(itemgetter(*subset_indices)(background_valid_filenames))\n",
    "bg_sounds = np.array([read_sound_file(f, (0, 2048)) for f in tqdm(background_train_sound_files)])\n",
    "mean, var, latent = sb_encoder.predict(bg_sounds)\n",
    "zeros = np.zeros_like(latent)\n",
    "decoder_input = np.concatenate((zeros, latent), axis=1)\n",
    "cvae_output = cvae_decoder.predict(decoder_input)\n",
    "loss = tf.keras.losses.mean_squared_error(hut_sounds, cvae_output)\n",
    "\n",
    "print(f'MSE loss for hive under test: {np.mean(loss)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Here we load train data sound samples and prepare spectrogram, periodogram and mfcc features (along with some data to visualize this). We should provide data with **utc timestamps** as it will be shifted with `timezone_offset_hours` var. What we also do is remove those samples which has strange rms signal. Threshold 0.8 was chosen based on `plot_distribution` output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "sound_time_ms = 2000\n",
    "# ~93 ms for fft window\n",
    "nfft = 4096\n",
    "# ~34% overlapping\n",
    "hop_len = (nfft//3) + 30\n",
    "# This can be manipulated to adjust number of bins for conv layer\n",
    "fmax = 2750\n",
    "\n",
    "hives_data = []\n",
    "rmses = {}\n",
    "max_to_norm = 0\n",
    "\n",
    "if DATA_INIT:\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        sound_files = [f for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_id}_*\\\\*.wav\")]\n",
    "        print(f\"Sound data preparation for hive: {hive_id} which has {len(sound_files)} recordings...\", end=' ', flush=True)\n",
    "        for file in tqdm(sound_files):\n",
    "            sample_rate, sound_samples = wavfile.read(file)\n",
    "            sound_samples = sound_samples.T[0]/(2.0**31)\n",
    "            rms = np.sqrt(sum(sound_samples**2)/len(sound_samples))\n",
    "            if rms < 0.7:    # that threshold was observed from plot_distribution() function\n",
    "                # calculate timestamp\n",
    "                filename = file.rsplit('\\\\', 1)[-1]\n",
    "                utc_timestamp = filename[filename.index('-')+1:].rsplit(\".wav\")[0]\n",
    "                sound_datetime = datetime.strptime(utc_timestamp, '%Y-%m-%dT%H-%M-%S') + timedelta(hours=timezone_offset_hours)\n",
    "                \n",
    "                # calculate mfcc feature\n",
    "                mfccs = librosa.feature.mfcc(y=sound_samples, sr=sample_rate, n_fft=nfft, hop_length=hop_len, n_mfcc=13)\n",
    "                np_mfcc_avg = np.mean(mfccs, axis=1)\n",
    "                \n",
    "                # calculate spectrogram\n",
    "                spectrogram = librosa.core.stft(sound_samples, n_fft=nfft, hop_length=hop_len)\n",
    "                spectrogram_magnitude = np.abs(spectrogram)\n",
    "                spectrogram_phase = np.angle(spectrogram)\n",
    "                spectrogram_db = librosa.amplitude_to_db(spectrogram_magnitude, ref=np.max)\n",
    "                frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=nfft)\n",
    "                times = (np.arange(0, spectrogram_magnitude.shape[1])*hop_len)/sample_rate\n",
    "                freq_slice = np.where((frequencies < fmax))\n",
    "                frequencies = frequencies[freq_slice]\n",
    "                spectrogram_db = spectrogram_db[freq_slice, :][0]\n",
    "                spectrogram_mean = np.mean(spectrogram_db, axis=1)\n",
    "                # decimate?\n",
    "                # spectrogram_db_decimated = decimate(spectrogram_db.T, 4).T\n",
    "                # frequencies_decimated = decimate(frequencies, 4)\n",
    "\n",
    "                #calculate periodogram\n",
    "                periodogram = fft(sound_samples, n=sample_rate)\n",
    "                periodogram = abs(periodogram[1:int(len(periodogram)/2)])\n",
    "                periodogram_freq = fftfreq(len(sound_samples)//(sound_time_ms//1000), 1/sample_rate)\n",
    "                periodogram_freq = periodogram_freq[:(len(periodogram_freq)//2)-1]\n",
    "                \n",
    "                hives_data.append(\n",
    "                    {\n",
    "                        'datetime': sound_datetime,\n",
    "                        'id': hive_id,\n",
    "                        'samples': sound_samples,\n",
    "                        'freq':\n",
    "                            {\n",
    "                                'spectrogram':\n",
    "                                    {\n",
    "                                        'frequencies': frequencies,\n",
    "                                        'time': times,\n",
    "                                        'spectrogram_full_db': spectrogram_db,\n",
    "                                        'spectrogram_mean': spectrogram_mean\n",
    "                                    },\n",
    "                                'periodogram':\n",
    "                                    {\n",
    "                                        'frequencies': periodogram_freq,\n",
    "                                        'samples': periodogram\n",
    "                                    }\n",
    "                            },\n",
    "                        'features':\n",
    "                            {\n",
    "                                'mfcc_avg': np_mfcc_avg\n",
    "                            }\n",
    "                    }\n",
    "                )\n",
    "        print(\" done.\")\n",
    "        \n",
    "    print(\"saving data on disc...\", end=' ')\n",
    "    np.save('data/raw_hives_data.npy', hives_data, allow_pickle=True)\n",
    "    print(\"done.\")\n",
    "else:\n",
    "    hives_data = np.load('data/raw_hives_data.npy', allow_pickle=True)\n",
    "    \n",
    "print(f\"got full dataset of {len(hives_data)} sound samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data preprocessing \n",
    "\n",
    "Here we perform scaling standarization etc.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "sc = StandardScaler()\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# extract every spectrogram from hives data list and standarize every periodogram from stft \n",
    "# so data for spectrogram will have zero mean and unit variance + scale every standarized periodogram\n",
    "print('preparing spectrograms...', end=' ', flush=True)\n",
    "spectrograms = [hive_data['freq']['spectrogram']['spectrogram_full_db'] for hive_data in hives_data]\n",
    "# standarized_spectrograms = [sc.fit_transform(spectrogram.T).T for spectrogram in tqdm(spectrograms)]\n",
    "scaled_spectrogram = [mm.fit_transform(spectrogram.T).T for spectrogram in tqdm(spectrograms, position=0, leave=True)]\n",
    "print('done.')\n",
    "\n",
    "# get datatime, names and mfcc\n",
    "print('getting mfccs', end=' ')\n",
    "datetimes = [hive_data['datetime'] for hive_data in hives_data]\n",
    "names = [hive_data['id'] for hive_data in hives_data]\n",
    "mfccs = [hive_data['features']['mfcc_avg'] for hive_data in hives_data]\n",
    "print('done.')\n",
    "\n",
    "# standarize and scale mean spectrogram for sounds\n",
    "print('preparing spectrogram means', end=' ')\n",
    "spectrograms_mean = [hive_data['freq']['spectrogram']['spectrogram_mean'] for hive_data in hives_data]\n",
    "standarized_spectrograms_mean = StandardScaler().fit_transform(spectrograms_mean)\n",
    "scaled_spectrograms_means = MinMaxScaler().fit_transform(standarized_spectrograms_mean)\n",
    "print('done.')\n",
    "\n",
    "# prepare truncated periodogram\n",
    "end_frequency = 2048\n",
    "print(f'preparing truncated periodograms ({end_frequency})', end=' ', flush=True)\n",
    "periodograms = [hive_data['freq']['periodogram']['samples'][:end_frequency] for hive_data in hives_data]\n",
    "periodograms = [mm.fit_transform(perio.reshape(-1, 1)).T for perio in tqdm(periodograms, position=0, leave=True)]\n",
    "print('done.')\n",
    "\n",
    "sounds = list(zip(scaled_spectrogram, mfccs, scaled_spectrograms_means, periodograms, datetimes, names))\n",
    "\n",
    "sounds_data = pd.DataFrame(sounds, columns=['spectrogram', 'mfccs', 'spectrogram_mean', 'periodogram', 'datetime', 'name'])\n",
    "sounds_data['datetime'] = pd.to_datetime(sounds_data['datetime'])\n",
    "sounds_hive_data = sounds_data[sounds_data['name'] == hive_under_analysis]\n",
    "\n",
    "print(f\"Got dataset of size: {len(sounds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CONTRASTIVE AE - keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds_data[sounds_data['name'] == 'smrpiclient7']['periodogram'].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.contrastive_keras import contrastive_keras_vae\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "target_keras = np.stack(sounds_data[sounds_data['name'] == 'smrpiclient7']['periodogram'].to_numpy()[:3000]).squeeze()\n",
    "background_keras = np.stack(sounds_data[sounds_data['name'] == 'smrpiclient6']['periodogram'].to_numpy()[:3000]).squeeze()\n",
    "\n",
    "print(f'training cvae (keras) with target of shape: {target_keras.shape} '\n",
    "    f'and background of shape: {background_keras.shape}')\n",
    "\n",
    "assert(target_keras.shape == background_keras.shape)\n",
    "\n",
    "cvae_keras, cvae_fg, z_encoder_keras, s_encoder_keras, cvae_keras_decoder = contrastive_keras_vae(\n",
    "    input_dim=2048, intermediate_dim=512, latent_dim=16, disentangle=True, gamma=1)\n",
    "history = cvae_keras.fit([target_keras, background_keras], epochs=50, batch_size=100, \n",
    "                         validation_data=([target_keras, background_keras], None), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train BASIC AE\n",
    "Here we train basic fully connected autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "\n",
    "from torch.utils import data as tdata\n",
    "from utils.data_utils import prepare_dataset1d\n",
    "from utils.autoencoder_utils import BasicAutoencoder, train_model\n",
    "\n",
    "TRAIN_MODEL = False\n",
    "PATH = 'basic_ae.pth'\n",
    "\n",
    "modelBasicAE = BasicAutoencoder().to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    train_dataloader, val_dataloader = prepare_dataset1d(sounds_hive_data['spectrogram_mean'], train_ratio=0.8, batch_size=64)\n",
    "    modelBasicAE = train_model(modelBasicAE,\n",
    "                           learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=20,\n",
    "                           dataloader_train=train_dataloader, dataloader_val=val_dataloader,\n",
    "                           checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelBasicAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CONV AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we train convolutional autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import data as tdata\n",
    "from utils.data_utils import prepare_dataset2d\n",
    "from utils.autoencoder_utils import ConvAutoencoder, train_model\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "PATH = 'conv_ae.pth'\n",
    "\n",
    "modelConvAE = ConvAutoencoder().to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    train_set, val_set = prepare_dataset2d(sounds_hive_data['spectrogram'], train_ratio=0.8)\n",
    "    \n",
    "    dataloader_train = tdata.DataLoader(train_set, batch_size=6, shuffle=True)\n",
    "    dataloader_val = tdata.DataLoader(val_set, batch_size=6, shuffle=True)\n",
    "    \n",
    "    modelConvAE = train_model(modelConvAE,\n",
    "                               learning_rate=1e-3, weight_decay=1e-6, num_epochs=100, patience=20,\n",
    "                               dataloader_train=dataloader_train, dataloader_val=dataloader_val,\n",
    "                               checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelConvAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no such file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train vae autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils import data as tdata\n",
    "from torchvision import transforms\n",
    "from utils.data_utils import prepare_dataset1d\n",
    "from utils.contrastive_pytorch import VAE, train_vae_model\n",
    "from utils.customdataset import CustomDataset\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "PATH = 'vae.pth'\n",
    "\n",
    "modelVAE = VAE(encoder_layer_sizes=[2048, 512, 64], latent_size=16, decoder_layer_sizes=[64, 512, 2048])\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    data = torch.Tensor(sounds_hive_data['periodogram'])\n",
    "    data = data[:, None, :]\n",
    "    idx_split = data.size(0)*80//100\n",
    "    train_dataset = CustomDataset(data[:idx_split], should_scale=True)\n",
    "    val_dataset = CustomDataset(data[idx_split:], should_scale=True)\n",
    "    train_dataloader = tdata.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_dataloader = tdata.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=100, patience=100,\n",
    "                              dataloader_train=train_dataloader, dataloader_val=val_dataloader, checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelVAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no such file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# read just sample file as probably all has the same sampling rate\n",
    "sample_rate, samples = wavfile.read('C:\\\\Users\\\\tymot\\\\projects\\\\001.smartula\\\\smartula-analysis\\\\smartula-analysis'\n",
    "                           '\\\\measurements\\\\smartulav2\\\\smrpiclient6_10082020-15092020\\\\DEADBEEF94-2020-08-10T03-11-50.wav')\n",
    "idx = random.randint(0, sounds_hive_data.shape[0] - 1)\n",
    "idx = 2240\n",
    "with torch.no_grad():   \n",
    "    modelConvAE.eval()\n",
    "    modelBasicAE.eval()\n",
    "    modelVAE.eval()\n",
    "    \n",
    "    # Get sound from sounds hive data (with respect to hive under analysis)\n",
    "    sound = sounds_hive_data.iloc[idx]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "    fig.suptitle(f'Convolutional Autoencoder real vs output for sample id: {idx}')\n",
    "    fig.tight_layout(pad = 3.0)\n",
    "\n",
    "    frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=nfft)\n",
    "    freq_slice = np.where((frequencies < fmax))\n",
    "    frequencies = frequencies[freq_slice]\n",
    "    times = (np.arange(0, sound['spectrogram'].shape[1])*hop_len)/sample_rate\n",
    "    elem = sound['spectrogram']\n",
    "    elem = elem[None, None, :, :]\n",
    "    elem = torch.Tensor(elem).to(device)\n",
    "    \n",
    "    elem_mean = sound['spectrogram_mean']\n",
    "    elem_mean = elem_mean[None, :]\n",
    "    elem_mean = torch.Tensor(elem_mean).to(device)\n",
    "    \n",
    "    axs[0][0].set_title('real spectrogram')\n",
    "    axs[0][0].pcolormesh(times, frequencies, sound['spectrogram'])\n",
    "    axs[0][1].set_title('encoded conv2d')\n",
    "    axs[0][1].pcolormesh(times, frequencies, modelConvAE(elem.to(device)).cpu().numpy().squeeze())\n",
    "    \n",
    "    # prepare data for vae prediction\n",
    "    freqs = np.arange(sound['periodogram'].shape[1])\n",
    "    input_data = torch.Tensor(sound['periodogram']).to(device)\n",
    "    vae_output, _, _ = modelVAE(input_data)\n",
    "    \n",
    "    # prepare data for cvae prediction\n",
    "    s_mean, s_log_var, s = s_encoder_keras.predict(sound['periodogram'])\n",
    "    latent = np.concatenate((np.zeros_like(s), s), axis = 1)\n",
    "    cvae_output = cvae_keras_decoder.predict(latent)\n",
    "\n",
    "    axs[1][0].set_title('spectrogram mean')\n",
    "    axs[1][0].plot(sound['spectrogram_mean'], label='real', color='blue')\n",
    "    axs[1][0].plot(modelBasicAE(elem_mean).cpu().numpy().squeeze(), label='encoded', color='red')\n",
    "    axs[1][0].legend()\n",
    "    \n",
    "    axs[1][1].set_title('periodogram')\n",
    "    axs[1][1].plot(freqs, periodogram_df, label='real', color='blue')\n",
    "    axs[1][1].plot(freqs, vae_output.cpu().numpy().squeeze(), label='vae encoded', color='red')\n",
    "    axs[1][1].plot(freqs, cvae_output.squeeze(), label='cvae encoded', color='green')\n",
    "    axs[1][1].legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add temperature/humidity/gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import read_sensor_data\n",
    "\n",
    "start_time = '2020-08-10 00:00:00'\n",
    "end_time = '2020-09-16 00:00:00'\n",
    "print(f\"extracting data for hive under analysis: {hive_under_analysis} from {start_time} to {end_time}...\")\n",
    "\n",
    "df_hives_sound = pd.DataFrame(sounds_data)\n",
    "df_hive_sound_ua = df_hives_sound[(df_hives_sound['name'] == hive_under_analysis)\n",
    "                                 & (df_hives_sound['datetime'] > start_time)\n",
    "                                 & (df_hives_sound['datetime'] < end_time)]\n",
    "df_hive_sound_ua.set_index('datetime', inplace=True)\n",
    "print(f\"-> prepared base of {df_hive_sound_ua.count()['spectrogram']} number of sound spectrums <-\")\n",
    "\n",
    "df_hive_temperature_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-temperature.csv',\n",
    "                                          hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'temperature')\n",
    "df_hive_humidity_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-humidity.csv',\n",
    "                                       hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'humidity')\n",
    "df_hive_alcohol_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-alcohol.csv',\n",
    "                                      hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'alcohol')\n",
    "df_hive_aceton_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-aceton.csv',\n",
    "                                     hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'aceton')\n",
    "df_hive_amon_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-jon-amonowy.csv',\n",
    "                                   hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'jon-amonowy')\n",
    "df_hive_toluen_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-toluen.csv',\n",
    "                                     hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'toluen')\n",
    "df_hive_co2_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-co2.csv',\n",
    "                                    hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'co2')\n",
    "df_hive_siarkowodor_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-siarkowodor.csv',\n",
    "                                          hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'siarkowodor')\n",
    "df_hive_metanotiol_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-metanotiol.csv',\n",
    "                                         hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'metanotiol')\n",
    "df_hive_trimetyloamina_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-trimetyloamina.csv',\n",
    "                                         hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'trimetyloamina')\n",
    "df_hive_wodor_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-wodor.csv',\n",
    "                                    hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'wodor')\n",
    "df_hive_co_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-co.csv',\n",
    "                                 hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'co')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check autocorrelation for specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import merge_dataframes_ontimestamp, merge_columns\n",
    "from utils.autoencoder_utils import conv2d_encode, basic_ae_encode\n",
    "from utils.contrastive_pytorch import vae_encode\n",
    "from utils.contrastive_keras import cvae_encode\n",
    "\n",
    "df_hive_data = merge_dataframes_ontimestamp(df_hive_sound_ua,\n",
    "                                            df_hive_temperature_ua, df_hive_humidity_ua,\n",
    "                                            df_hive_alcohol_ua, df_hive_aceton_ua, df_hive_amon_ua, df_hive_toluen_ua, df_hive_co2_ua,\n",
    "                                            df_hive_siarkowodor_ua, df_hive_metanotiol_ua, df_hive_trimetyloamina_ua, df_hive_wodor_ua,\n",
    "                                            df_hive_co_ua)\n",
    "\n",
    "df_hive_data['conv_ae'] = conv2d_encode(modelConvAE, df_hive_data['spectrogram'].to_list())\n",
    "df_hive_data['basic_ae'] = basic_ae_encode(modelBasicAE, df_hive_data['spectrogram_mean'].to_list())\n",
    "df_hive_data['vae'] = vae_encode(modelVAE, df_hive_data['periodogram'].to_list()).tolist()\n",
    "df_hive_data['cvae_s'] = cvae_encode(s_encoder_keras, df_hive_data['periodogram']).tolist()\n",
    "df_hive_data['cvae_z'] = cvae_encode(z_encoder_keras, df_hive_data['periodogram']).tolist()\n",
    "\n",
    "df_hive_data['bae_feature_vector'] = merge_columns(df_hive_data, ['basic_ae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['conv_feature_vector'] = merge_columns(df_hive_data, ['conv_ae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['mfcc_feature_vector'] = merge_columns(df_hive_data, ['mfccs', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['vae_feature_vector'] = merge_columns(df_hive_data, ['vae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['cvae_s_feature_vector'] = merge_columns(df_hive_data, ['cvae_s', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['cvae_z_feature_vector'] = merge_columns(df_hive_data, ['cvae_z', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.data_utils import search_best_night_day\n",
    "\n",
    "start_hours = [20, 21, 22, 23, 0, 1, 2, 3, 4]\n",
    "\n",
    "df_hive_data_scaled = pd.DataFrame(df_hive_data)\n",
    "\n",
    "# data for convolutional autoencoder\n",
    "df_hive_data_scaled['conv_feature_vector'] = StandardScaler().fit_transform(df_hive_data['conv_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for basic autoencoder\n",
    "df_hive_data_scaled['bae_feature_vector'] = StandardScaler().fit_transform(df_hive_data['bae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for mfcc features\n",
    "df_hive_data_scaled['mfcc_feature_vector'] = StandardScaler().fit_transform(df_hive_data['mfcc_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for vae features\n",
    "df_hive_data_scaled['vae_feature_vector'] = StandardScaler().fit_transform(df_hive_data['vae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for cvae s features\n",
    "df_hive_data_scaled['cvae_s_feature_vector'] = StandardScaler().fit_transform(df_hive_data['cvae_s_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for cvae s features\n",
    "df_hive_data_scaled['cvae_z_feature_vector'] = StandardScaler().fit_transform(df_hive_data['cvae_z_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for plain mfcc \n",
    "mfccs = [hive_data['features']['mfcc_avg'] for hive_data in hives_data if hive_data['id'] == hive_under_analysis]\n",
    "mfccs = StandardScaler().fit_transform(mfccs)\n",
    "datetimes = [hive_data['datetime'] for hive_data in hives_data if hive_data['id'] == hive_under_analysis]\n",
    "mfccs_data = list(zip(datetimes, mfccs))\n",
    "pd_mfcc_data = pd.DataFrame(mfccs_data, columns=['datetime', 'mfcc'])\n",
    "pd_mfcc_data.set_index('datetime', inplace=True)\n",
    "\n",
    "# calculate one class SVM match\n",
    "print('calculating mfccs match...', end=' ', flush=True)\n",
    "mfcc_accs = search_best_night_day(pd_mfcc_data, 'mfcc', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(mfcc_accs)}/{len(mfcc_accs[0])}')\n",
    "print('calculating conv ae feature vector match...', end=' ', flush=True)\n",
    "conv_ae_accs = search_best_night_day(df_hive_data_scaled, 'conv_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(conv_ae_accs)}/{len(conv_ae_accs[0])}')\n",
    "print('calculating basic ae feature vector match...', end=' ', flush=True)\n",
    "bae_accs = search_best_night_day(df_hive_data_scaled, 'bae_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(bae_accs)}/{len(bae_accs[0])}')\n",
    "print('calculating mfccs extended feature vector match...', end=' ', flush=True)\n",
    "mffce_accs = search_best_night_day(df_hive_data_scaled, 'mfcc_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(mffce_accs)}/{len(mffce_accs[0])}')\n",
    "print('calculating vae feature vector match...', end=' ', flush=True)\n",
    "vae_accs = search_best_night_day(df_hive_data_scaled, 'vae_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(vae_accs)}/{len(vae_accs[0])}')\n",
    "print('calculating cvae s feature vector match...', end=' ', flush=True)\n",
    "cvae_accs_s = search_best_night_day(df_hive_data_scaled, 'cvae_s_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(cvae_accs_s)}/{len(cvae_accs_s[0])}')\n",
    "print('calculating cvae z feature vector match...', end=' ', flush=True)\n",
    "cvae_accs_z = search_best_night_day(df_hive_data_scaled, 'cvae_z_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(cvae_accs_z)}/{len(cvae_accs_z[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import plot_hour_shift\n",
    "\n",
    "plot_hour_shift(mfcc_accs, conv_ae_accs, bae_accs, mffce_accs, vae_accs, cvae_accs_s, cvae_accs_z,\n",
    "                labels_list=['mfcc', 'conv', 'bae', 'mfcce', 'vae', 'cvae_s', 'cvae_z'],\n",
    "                xticklabels=[str(start_hour) for start_hour in start_hours],\n",
    "                save_path = 'data\\\\outputs\\\\zs_encoder_0_s.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize on 2D map, we basically perform TSNE and PCA dimension reduction in order to visualize night and day. Probably this will be not efficent but it is worth to give a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "start_hour = 23\n",
    "end_hour = 2\n",
    "\n",
    "reduce_df = pd.DataFrame(df_hive_data)\n",
    "reduce_df['feature_vector'] = StandardScaler().fit_transform(df_hive_data['bae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "reduced_ae_pca = PCA(n_components=2).fit_transform(reduce_df['feature_vector'].values.tolist())\n",
    "reduced_ae_tsne =  TSNE(n_components=2, perplexity=100, learning_rate=500).fit_transform(reduce_df['feature_vector'].values.tolist())\n",
    "is_night_list = (reduce_df.index.hour >= start_hour) | (reduce_df.index.hour <= end_hour)\n",
    "                \n",
    "colors = ['red', 'green', 'blue', 'yellow']\n",
    "labels = ['day', 'night']\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "\n",
    "axs[0].scatter(x=[data[0] for data in reduced_ae_pca],\n",
    "               y=[data[1] for data in reduced_ae_pca],\n",
    "               c=[colors[night] for night in is_night_list],\n",
    "              alpha=0.3)\n",
    "axs[0].set_title('PCA')\n",
    "\n",
    "axs[1].scatter(x=[data[0] for data in reduced_ae_tsne],\n",
    "               y=[data[1] for data in reduced_ae_tsne],\n",
    "               c=[colors[night] for night in is_night_list],\n",
    "              alpha=0.3)\n",
    "axs[1].set_title('TSNE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(reduce_df['feature_vector'].values.tolist())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def plot_distribution(distribution_dict, bin_size):\n",
    "    \"\"\" Plotting distribiution for dictionary elements\"\"\"\n",
    "    colors = ['blue', 'green', 'red', 'yellow', 'black', 'pink', 'purple']\n",
    "    rms_max = 0\n",
    "    rms_min = 65535\n",
    "    for k, v in rmses.items():\n",
    "        if np.max(v) > rms_max:\n",
    "            rms_max = np.max(v)\n",
    "        if np.min(v) < rms_min:\n",
    "            rms_min = np.min(v)\n",
    "        \n",
    "    plt.figure()\n",
    "    for idx, (k, v) in enumerate(distribution_dict.items()):\n",
    "        plt.hist(v, color=colors[idx%len(colors)], bins=int(np.abs(rms_max-rms_min)/bin_size))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of code for calculating autocorrelaction for specific feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "features = ['conv_ae', 'humidity', 'temperature',\n",
    "            'alcohol', 'aceton', 'jon-amonowy',\n",
    "            'toluen', 'co2', 'siarkowodor',\n",
    "            'metanotiol', 'trimetyloamina', 'wodor', 'co']\n",
    "\n",
    "feature = features[12]\n",
    "data_to_autocorr = df_hive_co_ua\n",
    "\n",
    "roll_len = 3\n",
    "interval = (data_to_autocorr.index[2] - data_to_autocorr.index[1]).seconds//60%60\n",
    "\n",
    "y2 = data_to_autocorr[feature].rolling(window=roll_len).mean().values\n",
    "y_corr = y2[roll_len:]\n",
    "x_corelation = np.arange(start=0, step=2, stop=150)\n",
    "\n",
    "fig, axes = plt.subplots(1, figsize=(8,5))\n",
    "x = plot_acf(y_corr, lags=x_corelation, zero=False, ax=axes)\n",
    "x_raw = acf(y_corr, nlags=150)\n",
    "axes.set_title(f'{feature} autocorrelaction')\n",
    "axes.set_xlabel(f'Lag (1 lag = {interval} minutes)') \n",
    "axes.set_ylabel('Correlation')\n",
    "axes.set_xticks(np.arange(0, 151, step=10))\n",
    "\n",
    "print(f'{feature} with max {max(x_raw[60:]):.2f} at {60 + np.argmax(x_raw[60:])}')\n",
    "\n",
    "# temperature with max 0.74 at 93 (15 mint)\n",
    "# humidity with max 0.58 at 92 (15 min)\n",
    "# alcohol with max 0.53 at 134 (10 min)\n",
    "# aceton with max 0.52 at 133 (10 min)\n",
    "# jon-amonowy with max 0.57 at 133 (10 min)\n",
    "# toluen with max 0.52 at 134 (10 min)\n",
    "# co2 with max 0.54 at 133 (10 min)\n",
    "# siarkowodor with max 0.16 at 142 (10 min)\n",
    "# metanotiol with max 0.34 at 140 (10 min)\n",
    "# trimetyloamina with max 0.56 at 138 (10 min)\n",
    "# wodor with max 0.14 at 142 (10 min)\n",
    "# co with max 0.62 at 134 (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.autoencoder_utils as ae\n",
    "import utils.data_utils as du\n",
    "import utils.customdataset as cd\n",
    "import utils.contrastive_pytorch as cp\n",
    "import utils.contrastive_keras as ck\n",
    "import utils.periodogram_dataset as pd\n",
    "\n",
    "importlib.reload(pd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
