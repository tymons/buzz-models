{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "hives_ids = [\"smrpiclient7\", \"smrpiclient6\", \"smrpiclient5\"]\n",
    "# hives_ids = [\"smrpiclient7\"]\n",
    "\n",
    "# define hive under analysis\n",
    "hive_under_analysis = hives_ids[0]\n",
    "# define offset as all data should be utc\n",
    "timezone_offset_hours = 2\n",
    "# define if we should reinit our data\n",
    "DATA_INIT = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'utils.periodogram_dataset_keras' from 'c:\\\\Users\\\\tymot\\\\projects\\\\001.smartula\\\\smartula-analysis\\\\smartula-analysis\\\\notebooks\\\\utils\\\\periodogram_dataset_keras.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "import utils.periodogram_dataset as pd\n",
    "import utils.periodogram_dataset_keras as pdk\n",
    "import utils.contrastive_pytorch as cp\n",
    "import utils.contrastive_keras as ck\n",
    "import utils.data_utils as du\n",
    "import importlib\n",
    "\n",
    "importlib.reload(du)\n",
    "importlib.reload(pdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "got 39678 sound filenames read for 5 files/folders\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import create_valid_sounds_datalist, get_valid_sounds_datalist\n",
    "\n",
    "CHECK_FILES = False                             # should we perform sound checking (long)\n",
    "\n",
    "root_folder = \"..\\\\measurements\\\\smartulav2\"    # root folder with folder containing sounds\n",
    "valid_filename = \"valid-files.txt\"              # filename for file which will be contain\n",
    "                                                # filenames for valid recordings\n",
    "checked_folders = []\n",
    "if CHECK_FILES:\n",
    "    checked_folders = create_valid_sounds_datalist(root_folder, valid_filename, \"smrpiclient\")\n",
    "else:\n",
    "     checked_folders = [os.path.join(root_folder, \"smrpiclient0_10082020-19012021\"),       \n",
    "                        os.path.join(root_folder, \"smrpiclient3_10082020-19012021\"), \n",
    "                        os.path.join(root_folder, \"smrpiclient5_10082020-19012021\"),    \n",
    "                        os.path.join(root_folder, \"smrpiclient6_10082020-19012021\"),\n",
    "                        os.path.join(root_folder, \"smrpiclient7_10082020-19012021\")]\n",
    "\n",
    "sound_filenames = get_valid_sounds_datalist(checked_folders, valid_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "24952 vs 39678\n"
     ]
    }
   ],
   "source": [
    "train_hives = [\"smrpiclient5\", \"smrpiclient6\", \"smrpiclient7\"]\n",
    "train_hives_soundfiles = list(filter(lambda filename: (any(hive in filename for hive in train_hives)), sound_filenames))\n",
    "print(f\"{len(train_hives_soundfiles)} vs {len(sound_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing train dataset with len: 23523\n",
      "VAE model training performed on cuda\n",
      "-> training at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [00:20<00:00, 12.57it/s]\n",
      "100%|██████████| 258/258 [00:20<00:00, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.89it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] train_loss: 1316.59128 valid_loss: 369.07854 checkpoint!\n",
      "-> training at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.52it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.88it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] train_loss: 366.98065 valid_loss: 365.45805 checkpoint!\n",
      "-> training at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:12<00:00, 20.23it/s]\n",
      "100%|██████████| 258/258 [00:12<00:00, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:12<00:00, 20.86it/s]\n",
      "100%|██████████| 258/258 [00:12<00:00, 20.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/10] train_loss: 362.47415 valid_loss: 363.27328 checkpoint!\n",
      "-> training at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.60it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.73it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/10] train_loss: 361.11007 valid_loss: 358.32089 checkpoint!\n",
      "-> training at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:12<00:00, 21.49it/s]\n",
      "100%|██████████| 258/258 [00:12<00:00, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.02it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/10] train_loss: 358.71444 valid_loss: 361.14823 .\n",
      "-> training at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.78it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.52it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/10] train_loss: 357.81459 valid_loss: 355.48840 checkpoint!\n",
      "-> training at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.18it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.76it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/10] train_loss: 356.08914 valid_loss: 354.73231 checkpoint!\n",
      "-> training at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.90it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.49it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/10] train_loss: 350.44952 valid_loss: 348.27955 checkpoint!\n",
      "-> training at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.23it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.31it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/10] train_loss: 347.67809 valid_loss: 345.44434 checkpoint!\n",
      "-> training at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.79it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> validating at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.97it/s]\n",
      "100%|██████████| 258/258 [00:11<00:00, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] train_loss: 344.85502 valid_loss: 342.45989 checkpoint!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils.periodogram_dataset import PeriodogramDataset\n",
    "from utils.contrastive_pytorch import VAE, train_vae_model\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'models\\\\vae-apprirary-approach-10022021.pth'\n",
    "TRAIN = True\n",
    "\n",
    "modelVAE = VAE(encoder_layer_sizes=[2048, 512, 64], \\\n",
    "                latent_size=16, decoder_layer_sizes=[64, 512, 2048]).to(device)\n",
    "\n",
    "if TRAIN:\n",
    "    print(f\"preparing train dataset with len: {len(sound_filenames)}\")\n",
    "    dataset = PeriodogramDataset(sound_files, hives_ids, slice_freq=(0, 2048))\n",
    "    val_amount = int(dataset.__len__() * 0.15)\n",
    "    train_set, val_set = random_split(dataset, [(dataset.__len__() - val_amount)), val_amount])\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "    modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=100,\n",
    "                                  dataloader_train=train_loader, dataloader_val=val_loader, checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelVAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smrpiclient7'] vs ['smrpiclient6', 'smrpiclient5']\n",
      "['smrpiclient6'] vs ['smrpiclient7', 'smrpiclient5']\n",
      "['smrpiclient5'] vs ['smrpiclient7', 'smrpiclient6']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "from utils.periodogram_dataset_keras import PeriodogramGenerator\n",
    "from utils.contrastive_keras import contrastive_keras_vae\n",
    "from tensorflow import keras\n",
    "\n",
    "bsize = 64\n",
    "TRAIN = True\n",
    "MIXED = True\n",
    "\n",
    "# background_hives = [\"smrpiclient6\", \"smrpiclient5\"]\n",
    "# target_hives = [\"smrpiclient7\"]\n",
    "\n",
    "cvae_keras, _, _, _, sb_encoder, cvae_decoder = contrastive_keras_vae(input_dim=2048, intermediate_dim=[512, 64], latent_dim=16,\n",
    "                                                   disentangle=True, gamma=1, batch_size=bsize)\n",
    "    \n",
    "if TRAIN:        \n",
    "    for idx in range(len(hives_ids)):\n",
    "        # loop for all variants for background data\n",
    "        cvae_hives = list(hives_ids) # temporary list\n",
    "        target_hives = [cvae_hives.pop(idx)]\n",
    "        background_hives = cvae_hives\n",
    "        \n",
    "        # load target data\n",
    "        target_valid_file = [f for target_hive in target_hives for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{cvae_hives}_*\\\\valid-files.txt\")]\n",
    "        target_valid_filenames = []\n",
    "        for valid_file in target_valid_files:\n",
    "            with open(valid_file, 'r') as f:\n",
    "                target_valid_filenames += f.read().splitlines()\n",
    "    \n",
    "        # load background data\n",
    "        background_valid_files = [f for background_hive in background_hives for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{background_hive}_*\\\\valid-files.txt\")]\n",
    "        background_valid_filenames = []\n",
    "        for background_valid_file in background_valid_files:\n",
    "            with open(background_valid_file, 'r') as f:\n",
    "                background_valid_filenames += f.read().splitlines()\n",
    "        background_valid_filenames = background_valid_filenames[:len(target_valid_filenames)]\n",
    "        \n",
    "        # Prepare dataset and train\n",
    "        train_generator = PeriodogramGenerator(target_valid_filenames, background_valid_filenames,\n",
    "                                               batch_size=bsize, labels=[target_hive], slice_freq=(0, 2048))\n",
    "        history = cvae_keras.fit(train_generator, epochs=10, batch_size=bsize, verbose=1)\n",
    "    \n",
    "        cvae_keras.save_weights('models/cvae_keras_weights_10022021.h5')\n",
    "        sb_encoder.save_weights('models/sb_encoder_weights_10022021.h5')\n",
    "        cvae_decoder.save_weights('models/cvae_decoder_weights_10022021.h5')\n",
    "else:\n",
    "    cvae_keras.load_weights('models/cvae_keras_weights_10022021.h5')\n",
    "    sb_encoder.load_weights('models/sb_encoder_weights_10022021.h5')\n",
    "    cvae_decoder.load_weights('models/cvae_decoder_weights_10022021.h5')\n",
    "    print(f'model loaded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:08<00:00, 298.56it/s]\n",
      "  2%|▏         | 46/2452 [00:00<00:10, 226.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:08<00:00, 274.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss vs train loss : 0.005118480417877436 : 0.0038946554996073246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.periodogram_dataset import PeriodogramDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data_utils import normal_pdf\n",
    "\n",
    "hives_ids_test = [\"smrpiclient3\"]\n",
    "hut_sounds_files = [f for hive_name_test in hives_ids_test for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name_test}_*\\\\*.wav\")]\n",
    "all_sound_files = [f for hive_name in hives_ids for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name}_*\\\\*.wav\")]\n",
    "\n",
    "# pytorch\n",
    "hut_dataset = PeriodogramDataset(hut_sounds_files, hives_ids_test, slice_freq=(0, 2048))\n",
    "all_sound_dataset = PeriodogramDataset(all_sound_files, hives_ids, slice_freq=(0, 2048))\n",
    "\n",
    "# get indices for all_sound_dataset\n",
    "subset_indices = np.random.randint(0, len(all_sound_dataset), len(hut_dataset))\n",
    "dataset = torch.utils.data.Subset(all_sound_dataset, subset_indices)\n",
    "\n",
    "test_loss = []\n",
    "train_loss = []\n",
    "with torch.no_grad():\n",
    "    modelVAE.eval()\n",
    "    print(f'validating on test set', flush=True)\n",
    "    for input_data in tqdm(hut_dataset, position=0, leave=True):\n",
    "        if input_data:\n",
    "            input_data = torch.Tensor(input_data[0]).to(device)\n",
    "            output, mean, var = modelVAE(input_data.to(device))\n",
    "            test_loss.append(F.mse_loss(output, input_data).cpu().numpy())\n",
    "            \n",
    "    print(f'validating on training set')\n",
    "    for input_data in tqdm(dataset, position=0, leave=True):\n",
    "        if input_data:\n",
    "            input_data = torch.Tensor(input_data[0]).to(device)\n",
    "            output, _, _ = modelVAE(input_data.to(device))\n",
    "            train_loss.append(F.mse_loss(output, input_data).cpu().numpy())\n",
    "                \n",
    "test_loss_avg = np.mean(test_loss)\n",
    "train_loss_avg = np.mean(train_loss)\n",
    "                                       \n",
    "print(f'test loss vs train loss : {test_loss_avg} : {train_loss_avg}')\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:03<00:00, 797.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss for hive under test: 0.004782302770763636\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from operator import itemgetter \n",
    "from utils.periodogram_dataset_keras import PeriodogramGenerator, read_sound_file\n",
    "from tqdm import tqdm \n",
    "\n",
    "hut_sounds =  np.array([read_sound_file(f, (0, 2048)) for f in tqdm(hut_sounds_files)])\n",
    "mean, var, latent = sb_encoder.predict(hut_sounds)\n",
    "zeros = np.zeros_like(latent)\n",
    "decoder_input = np.concatenate((zeros, latent), axis=1)\n",
    "cvae_output = cvae_decoder.predict(decoder_input)\n",
    "loss = tf.keras.losses.mean_squared_error(hut_sounds, cvae_output)\n",
    "\n",
    "print(f'MSE loss for hive under test: {np.mean(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:03<00:00, 695.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss for background test: 0.0020129058975726366\n"
     ]
    }
   ],
   "source": [
    "subset_indices = np.random.randint(0, len(background_valid_filenames), len(hut_sounds))\n",
    "\n",
    "background_train_sound_files = list(itemgetter(*subset_indices)(background_valid_filenames))\n",
    "bg_sounds = np.array([read_sound_file(f, (0, 2048)) for f in tqdm(background_train_sound_files)])\n",
    "mean, var, latent = sb_encoder.predict(bg_sounds)\n",
    "zeros = np.zeros_like(latent)\n",
    "decoder_input = np.concatenate((zeros, latent), axis=1)\n",
    "cvae_output = cvae_decoder.predict(decoder_input)\n",
    "loss = tf.keras.losses.mean_squared_error(bg_sounds, cvae_output)\n",
    "\n",
    "print(f'MSE loss for background test: {np.mean(loss)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Here we load train data sound samples and prepare spectrogram, periodogram and mfcc features (along with some data to visualize this). We should provide data with **utc timestamps** as it will be shifted with `timezone_offset_hours` var. What we also do is remove those samples which has strange rms signal. Threshold 0.8 was chosen based on `plot_distribution` output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "sound_time_ms = 2000\n",
    "# ~93 ms for fft window\n",
    "nfft = 4096\n",
    "# ~34% overlapping\n",
    "hop_len = (nfft//3) + 30\n",
    "# This can be manipulated to adjust number of bins for conv layer\n",
    "fmax = 2750\n",
    "\n",
    "hives_data = []\n",
    "rmses = {}\n",
    "max_to_norm = 0\n",
    "\n",
    "if DATA_INIT:\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        sound_files = [f for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_id}_*\\\\*.wav\")]\n",
    "        print(f\"Sound data preparation for hive: {hive_id} which has {len(sound_files)} recordings...\", end=' ', flush=True)\n",
    "        for file in tqdm(sound_files):\n",
    "            sample_rate, sound_samples = wavfile.read(file)\n",
    "            sound_samples = sound_samples.T[0]/(2.0**31)\n",
    "            rms = np.sqrt(sum(sound_samples**2)/len(sound_samples))\n",
    "            if rms < 0.7:    # that threshold was observed from plot_distribution() function\n",
    "                # calculate timestamp\n",
    "                filename = file.rsplit('\\\\', 1)[-1]\n",
    "                utc_timestamp = filename[filename.index('-')+1:].rsplit(\".wav\")[0]\n",
    "                sound_datetime = datetime.strptime(utc_timestamp, '%Y-%m-%dT%H-%M-%S') + timedelta(hours=timezone_offset_hours)\n",
    "                \n",
    "                # calculate mfcc feature\n",
    "                mfccs = librosa.feature.mfcc(y=sound_samples, sr=sample_rate, n_fft=nfft, hop_length=hop_len, n_mfcc=13)\n",
    "                np_mfcc_avg = np.mean(mfccs, axis=1)\n",
    "                \n",
    "                # calculate spectrogram\n",
    "                spectrogram = librosa.core.stft(sound_samples, n_fft=nfft, hop_length=hop_len)\n",
    "                spectrogram_magnitude = np.abs(spectrogram)\n",
    "                spectrogram_phase = np.angle(spectrogram)\n",
    "                spectrogram_db = librosa.amplitude_to_db(spectrogram_magnitude, ref=np.max)\n",
    "                frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=nfft)\n",
    "                times = (np.arange(0, spectrogram_magnitude.shape[1])*hop_len)/sample_rate\n",
    "                freq_slice = np.where((frequencies < fmax))\n",
    "                frequencies = frequencies[freq_slice]\n",
    "                spectrogram_db = spectrogram_db[freq_slice, :][0]\n",
    "                spectrogram_mean = np.mean(spectrogram_db, axis=1)\n",
    "                # decimate?\n",
    "                # spectrogram_db_decimated = decimate(spectrogram_db.T, 4).T\n",
    "                # frequencies_decimated = decimate(frequencies, 4)\n",
    "\n",
    "                #calculate periodogram\n",
    "                periodogram = fft(sound_samples, n=sample_rate)\n",
    "                periodogram = abs(periodogram[1:int(len(periodogram)/2)])\n",
    "                periodogram_freq = fftfreq(len(sound_samples)//(sound_time_ms//1000), 1/sample_rate)\n",
    "                periodogram_freq = periodogram_freq[:(len(periodogram_freq)//2)-1]\n",
    "                \n",
    "                hives_data.append(\n",
    "                    {\n",
    "                        'datetime': sound_datetime,\n",
    "                        'id': hive_id,\n",
    "                        'samples': sound_samples,\n",
    "                        'freq':\n",
    "                            {\n",
    "                                'spectrogram':\n",
    "                                    {\n",
    "                                        'frequencies': frequencies,\n",
    "                                        'time': times,\n",
    "                                        'spectrogram_full_db': spectrogram_db,\n",
    "                                        'spectrogram_mean': spectrogram_mean\n",
    "                                    },\n",
    "                                'periodogram':\n",
    "                                    {\n",
    "                                        'frequencies': periodogram_freq,\n",
    "                                        'samples': periodogram\n",
    "                                    }\n",
    "                            },\n",
    "                        'features':\n",
    "                            {\n",
    "                                'mfcc_avg': np_mfcc_avg\n",
    "                            }\n",
    "                    }\n",
    "                )\n",
    "        print(\" done.\")\n",
    "        \n",
    "    print(\"saving data on disc...\", end=' ')\n",
    "    np.save('data/raw_hives_data.npy', hives_data, allow_pickle=True)\n",
    "    print(\"done.\")\n",
    "else:\n",
    "    hives_data = np.load('data/raw_hives_data.npy', allow_pickle=True)\n",
    "    \n",
    "print(f\"got full dataset of {len(hives_data)} sound samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data preprocessing \n",
    "\n",
    "Here we perform scaling standarization etc.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "sc = StandardScaler()\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# extract every spectrogram from hives data list and standarize every periodogram from stft \n",
    "# so data for spectrogram will have zero mean and unit variance + scale every standarized periodogram\n",
    "print('preparing spectrograms...', end=' ', flush=True)\n",
    "spectrograms = [hive_data['freq']['spectrogram']['spectrogram_full_db'] for hive_data in hives_data]\n",
    "# standarized_spectrograms = [sc.fit_transform(spectrogram.T).T for spectrogram in tqdm(spectrograms)]\n",
    "scaled_spectrogram = [mm.fit_transform(spectrogram.T).T for spectrogram in tqdm(spectrograms, position=0, leave=True)]\n",
    "print('done.')\n",
    "\n",
    "# get datatime, names and mfcc\n",
    "print('getting mfccs', end=' ')\n",
    "datetimes = [hive_data['datetime'] for hive_data in hives_data]\n",
    "names = [hive_data['id'] for hive_data in hives_data]\n",
    "mfccs = [hive_data['features']['mfcc_avg'] for hive_data in hives_data]\n",
    "print('done.')\n",
    "\n",
    "# standarize and scale mean spectrogram for sounds\n",
    "print('preparing spectrogram means', end=' ')\n",
    "spectrograms_mean = [hive_data['freq']['spectrogram']['spectrogram_mean'] for hive_data in hives_data]\n",
    "standarized_spectrograms_mean = StandardScaler().fit_transform(spectrograms_mean)\n",
    "scaled_spectrograms_means = MinMaxScaler().fit_transform(standarized_spectrograms_mean)\n",
    "print('done.')\n",
    "\n",
    "# prepare truncated periodogram\n",
    "end_frequency = 2048\n",
    "print(f'preparing truncated periodograms ({end_frequency})', end=' ', flush=True)\n",
    "periodograms = [hive_data['freq']['periodogram']['samples'][:end_frequency] for hive_data in hives_data]\n",
    "periodograms = [mm.fit_transform(perio.reshape(-1, 1)).T for perio in tqdm(periodograms, position=0, leave=True)]\n",
    "print('done.')\n",
    "\n",
    "sounds = list(zip(scaled_spectrogram, mfccs, scaled_spectrograms_means, periodograms, datetimes, names))\n",
    "\n",
    "sounds_data = pd.DataFrame(sounds, columns=['spectrogram', 'mfccs', 'spectrogram_mean', 'periodogram', 'datetime', 'name'])\n",
    "sounds_data['datetime'] = pd.to_datetime(sounds_data['datetime'])\n",
    "sounds_hive_data = sounds_data[sounds_data['name'] == hive_under_analysis]\n",
    "\n",
    "print(f\"Got dataset of size: {len(sounds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CONTRASTIVE AE - keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds_data[sounds_data['name'] == 'smrpiclient7']['periodogram'].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.contrastive_keras import contrastive_keras_vae\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "target_keras = np.stack(sounds_data[sounds_data['name'] == 'smrpiclient7']['periodogram'].to_numpy()[:3000]).squeeze()\n",
    "background_keras = np.stack(sounds_data[sounds_data['name'] == 'smrpiclient6']['periodogram'].to_numpy()[:3000]).squeeze()\n",
    "\n",
    "print(f'training cvae (keras) with target of shape: {target_keras.shape} '\n",
    "    f'and background of shape: {background_keras.shape}')\n",
    "\n",
    "assert(target_keras.shape == background_keras.shape)\n",
    "\n",
    "cvae_keras, cvae_fg, z_encoder_keras, s_encoder_keras, cvae_keras_decoder = contrastive_keras_vae(\n",
    "    input_dim=2048, intermediate_dim=512, latent_dim=16, disentangle=True, gamma=1)\n",
    "history = cvae_keras.fit([target_keras, background_keras], epochs=50, batch_size=100, \n",
    "                         validation_data=([target_keras, background_keras], None), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train BASIC AE\n",
    "Here we train basic fully connected autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "\n",
    "from torch.utils import data as tdata\n",
    "from utils.data_utils import prepare_dataset1d\n",
    "from utils.autoencoder_utils import BasicAutoencoder, train_model\n",
    "\n",
    "TRAIN_MODEL = False\n",
    "PATH = 'basic_ae.pth'\n",
    "\n",
    "modelBasicAE = BasicAutoencoder().to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    train_dataloader, val_dataloader = prepare_dataset1d(sounds_hive_data['spectrogram_mean'], train_ratio=0.8, batch_size=64)\n",
    "    modelBasicAE = train_model(modelBasicAE,\n",
    "                           learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=20,\n",
    "                           dataloader_train=train_dataloader, dataloader_val=val_dataloader,\n",
    "                           checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelBasicAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CONV AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we train convolutional autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import data as tdata\n",
    "from utils.data_utils import prepare_dataset2d\n",
    "from utils.autoencoder_utils import ConvAutoencoder, train_model\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "PATH = 'conv_ae.pth'\n",
    "\n",
    "modelConvAE = ConvAutoencoder().to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    train_set, val_set = prepare_dataset2d(sounds_hive_data['spectrogram'], train_ratio=0.8)\n",
    "    \n",
    "    dataloader_train = tdata.DataLoader(train_set, batch_size=6, shuffle=True)\n",
    "    dataloader_val = tdata.DataLoader(val_set, batch_size=6, shuffle=True)\n",
    "    \n",
    "    modelConvAE = train_model(modelConvAE,\n",
    "                               learning_rate=1e-3, weight_decay=1e-6, num_epochs=100, patience=20,\n",
    "                               dataloader_train=dataloader_train, dataloader_val=dataloader_val,\n",
    "                               checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelConvAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no such file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train vae autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils import data as tdata\n",
    "from torchvision import transforms\n",
    "from utils.data_utils import prepare_dataset1d\n",
    "from utils.contrastive_pytorch import VAE, train_vae_model\n",
    "from utils.customdataset import CustomDataset\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "PATH = 'vae.pth'\n",
    "\n",
    "modelVAE = VAE(encoder_layer_sizes=[2048, 512, 64], latent_size=16, decoder_layer_sizes=[64, 512, 2048])\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    data = torch.Tensor(sounds_hive_data['periodogram'])\n",
    "    data = data[:, None, :]\n",
    "    idx_split = data.size(0)*80//100\n",
    "    train_dataset = CustomDataset(data[:idx_split], should_scale=True)\n",
    "    val_dataset = CustomDataset(data[idx_split:], should_scale=True)\n",
    "    train_dataloader = tdata.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_dataloader = tdata.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=100, patience=100,\n",
    "                              dataloader_train=train_dataloader, dataloader_val=val_dataloader, checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelVAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no such file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# read just sample file as probably all has the same sampling rate\n",
    "sample_rate, samples = wavfile.read('C:\\\\Users\\\\tymot\\\\projects\\\\001.smartula\\\\smartula-analysis\\\\smartula-analysis'\n",
    "                           '\\\\measurements\\\\smartulav2\\\\smrpiclient6_10082020-15092020\\\\DEADBEEF94-2020-08-10T03-11-50.wav')\n",
    "idx = random.randint(0, sounds_hive_data.shape[0] - 1)\n",
    "idx = 2240\n",
    "with torch.no_grad():   \n",
    "    modelConvAE.eval()\n",
    "    modelBasicAE.eval()\n",
    "    modelVAE.eval()\n",
    "    \n",
    "    # Get sound from sounds hive data (with respect to hive under analysis)\n",
    "    sound = sounds_hive_data.iloc[idx]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "    fig.suptitle(f'Convolutional Autoencoder real vs output for sample id: {idx}')\n",
    "    fig.tight_layout(pad = 3.0)\n",
    "\n",
    "    frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=nfft)\n",
    "    freq_slice = np.where((frequencies < fmax))\n",
    "    frequencies = frequencies[freq_slice]\n",
    "    times = (np.arange(0, sound['spectrogram'].shape[1])*hop_len)/sample_rate\n",
    "    elem = sound['spectrogram']\n",
    "    elem = elem[None, None, :, :]\n",
    "    elem = torch.Tensor(elem).to(device)\n",
    "    \n",
    "    elem_mean = sound['spectrogram_mean']\n",
    "    elem_mean = elem_mean[None, :]\n",
    "    elem_mean = torch.Tensor(elem_mean).to(device)\n",
    "    \n",
    "    axs[0][0].set_title('real spectrogram')\n",
    "    axs[0][0].pcolormesh(times, frequencies, sound['spectrogram'])\n",
    "    axs[0][1].set_title('encoded conv2d')\n",
    "    axs[0][1].pcolormesh(times, frequencies, modelConvAE(elem.to(device)).cpu().numpy().squeeze())\n",
    "    \n",
    "    # prepare data for vae prediction\n",
    "    freqs = np.arange(sound['periodogram'].shape[1])\n",
    "    input_data = torch.Tensor(sound['periodogram']).to(device)\n",
    "    vae_output, _, _ = modelVAE(input_data)\n",
    "    \n",
    "    # prepare data for cvae prediction\n",
    "    s_mean, s_log_var, s = s_encoder_keras.predict(sound['periodogram'])\n",
    "    latent = np.concatenate((np.zeros_like(s), s), axis = 1)\n",
    "    cvae_output = cvae_keras_decoder.predict(latent)\n",
    "\n",
    "    axs[1][0].set_title('spectrogram mean')\n",
    "    axs[1][0].plot(sound['spectrogram_mean'], label='real', color='blue')\n",
    "    axs[1][0].plot(modelBasicAE(elem_mean).cpu().numpy().squeeze(), label='encoded', color='red')\n",
    "    axs[1][0].legend()\n",
    "    \n",
    "    axs[1][1].set_title('periodogram')\n",
    "    axs[1][1].plot(freqs, periodogram_df, label='real', color='blue')\n",
    "    axs[1][1].plot(freqs, vae_output.cpu().numpy().squeeze(), label='vae encoded', color='red')\n",
    "    axs[1][1].plot(freqs, cvae_output.squeeze(), label='cvae encoded', color='green')\n",
    "    axs[1][1].legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add temperature/humidity/gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import read_sensor_data\n",
    "\n",
    "start_time = '2020-08-10 00:00:00'\n",
    "end_time = '2020-09-16 00:00:00'\n",
    "print(f\"extracting data for hive under analysis: {hive_under_analysis} from {start_time} to {end_time}...\")\n",
    "\n",
    "df_hives_sound = pd.DataFrame(sounds_data)\n",
    "df_hive_sound_ua = df_hives_sound[(df_hives_sound['name'] == hive_under_analysis)\n",
    "                                 & (df_hives_sound['datetime'] > start_time)\n",
    "                                 & (df_hives_sound['datetime'] < end_time)]\n",
    "df_hive_sound_ua.set_index('datetime', inplace=True)\n",
    "print(f\"-> prepared base of {df_hive_sound_ua.count()['spectrogram']} number of sound spectrums <-\")\n",
    "\n",
    "df_hive_temperature_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-temperature.csv',\n",
    "                                          hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'temperature')\n",
    "df_hive_humidity_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-humidity.csv',\n",
    "                                       hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'humidity')\n",
    "df_hive_alcohol_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-alcohol.csv',\n",
    "                                      hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'alcohol')\n",
    "df_hive_aceton_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-aceton.csv',\n",
    "                                     hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'aceton')\n",
    "df_hive_amon_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-jon-amonowy.csv',\n",
    "                                   hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'jon-amonowy')\n",
    "df_hive_toluen_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-toluen.csv',\n",
    "                                     hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'toluen')\n",
    "df_hive_co2_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-co2.csv',\n",
    "                                    hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'co2')\n",
    "df_hive_siarkowodor_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-siarkowodor.csv',\n",
    "                                          hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'siarkowodor')\n",
    "df_hive_metanotiol_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-metanotiol.csv',\n",
    "                                         hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'metanotiol')\n",
    "df_hive_trimetyloamina_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-trimetyloamina.csv',\n",
    "                                         hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'trimetyloamina')\n",
    "df_hive_wodor_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-wodor.csv',\n",
    "                                    hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'wodor')\n",
    "df_hive_co_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-co.csv',\n",
    "                                 hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'co')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check autocorrelation for specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import merge_dataframes_ontimestamp, merge_columns\n",
    "from utils.autoencoder_utils import conv2d_encode, basic_ae_encode\n",
    "from utils.contrastive_pytorch import vae_encode\n",
    "from utils.contrastive_keras import cvae_encode\n",
    "\n",
    "df_hive_data = merge_dataframes_ontimestamp(df_hive_sound_ua,\n",
    "                                            df_hive_temperature_ua, df_hive_humidity_ua,\n",
    "                                            df_hive_alcohol_ua, df_hive_aceton_ua, df_hive_amon_ua, df_hive_toluen_ua, df_hive_co2_ua,\n",
    "                                            df_hive_siarkowodor_ua, df_hive_metanotiol_ua, df_hive_trimetyloamina_ua, df_hive_wodor_ua,\n",
    "                                            df_hive_co_ua)\n",
    "\n",
    "df_hive_data['conv_ae'] = conv2d_encode(modelConvAE, df_hive_data['spectrogram'].to_list())\n",
    "df_hive_data['basic_ae'] = basic_ae_encode(modelBasicAE, df_hive_data['spectrogram_mean'].to_list())\n",
    "df_hive_data['vae'] = vae_encode(modelVAE, df_hive_data['periodogram'].to_list()).tolist()\n",
    "df_hive_data['cvae_s'] = cvae_encode(s_encoder_keras, df_hive_data['periodogram']).tolist()\n",
    "df_hive_data['cvae_z'] = cvae_encode(z_encoder_keras, df_hive_data['periodogram']).tolist()\n",
    "\n",
    "df_hive_data['bae_feature_vector'] = merge_columns(df_hive_data, ['basic_ae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['conv_feature_vector'] = merge_columns(df_hive_data, ['conv_ae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['mfcc_feature_vector'] = merge_columns(df_hive_data, ['mfccs', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['vae_feature_vector'] = merge_columns(df_hive_data, ['vae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['cvae_s_feature_vector'] = merge_columns(df_hive_data, ['cvae_s', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['cvae_z_feature_vector'] = merge_columns(df_hive_data, ['cvae_z', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.data_utils import search_best_night_day\n",
    "\n",
    "start_hours = [20, 21, 22, 23, 0, 1, 2, 3, 4]\n",
    "\n",
    "df_hive_data_scaled = pd.DataFrame(df_hive_data)\n",
    "\n",
    "# data for convolutional autoencoder\n",
    "df_hive_data_scaled['conv_feature_vector'] = StandardScaler().fit_transform(df_hive_data['conv_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for basic autoencoder\n",
    "df_hive_data_scaled['bae_feature_vector'] = StandardScaler().fit_transform(df_hive_data['bae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for mfcc features\n",
    "df_hive_data_scaled['mfcc_feature_vector'] = StandardScaler().fit_transform(df_hive_data['mfcc_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for vae features\n",
    "df_hive_data_scaled['vae_feature_vector'] = StandardScaler().fit_transform(df_hive_data['vae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for cvae s features\n",
    "df_hive_data_scaled['cvae_s_feature_vector'] = StandardScaler().fit_transform(df_hive_data['cvae_s_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for cvae s features\n",
    "df_hive_data_scaled['cvae_z_feature_vector'] = StandardScaler().fit_transform(df_hive_data['cvae_z_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for plain mfcc \n",
    "mfccs = [hive_data['features']['mfcc_avg'] for hive_data in hives_data if hive_data['id'] == hive_under_analysis]\n",
    "mfccs = StandardScaler().fit_transform(mfccs)\n",
    "datetimes = [hive_data['datetime'] for hive_data in hives_data if hive_data['id'] == hive_under_analysis]\n",
    "mfccs_data = list(zip(datetimes, mfccs))\n",
    "pd_mfcc_data = pd.DataFrame(mfccs_data, columns=['datetime', 'mfcc'])\n",
    "pd_mfcc_data.set_index('datetime', inplace=True)\n",
    "\n",
    "# calculate one class SVM match\n",
    "print('calculating mfccs match...', end=' ', flush=True)\n",
    "mfcc_accs = search_best_night_day(pd_mfcc_data, 'mfcc', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(mfcc_accs)}/{len(mfcc_accs[0])}')\n",
    "print('calculating conv ae feature vector match...', end=' ', flush=True)\n",
    "conv_ae_accs = search_best_night_day(df_hive_data_scaled, 'conv_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(conv_ae_accs)}/{len(conv_ae_accs[0])}')\n",
    "print('calculating basic ae feature vector match...', end=' ', flush=True)\n",
    "bae_accs = search_best_night_day(df_hive_data_scaled, 'bae_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(bae_accs)}/{len(bae_accs[0])}')\n",
    "print('calculating mfccs extended feature vector match...', end=' ', flush=True)\n",
    "mffce_accs = search_best_night_day(df_hive_data_scaled, 'mfcc_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(mffce_accs)}/{len(mffce_accs[0])}')\n",
    "print('calculating vae feature vector match...', end=' ', flush=True)\n",
    "vae_accs = search_best_night_day(df_hive_data_scaled, 'vae_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(vae_accs)}/{len(vae_accs[0])}')\n",
    "print('calculating cvae s feature vector match...', end=' ', flush=True)\n",
    "cvae_accs_s = search_best_night_day(df_hive_data_scaled, 'cvae_s_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(cvae_accs_s)}/{len(cvae_accs_s[0])}')\n",
    "print('calculating cvae z feature vector match...', end=' ', flush=True)\n",
    "cvae_accs_z = search_best_night_day(df_hive_data_scaled, 'cvae_z_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(cvae_accs_z)}/{len(cvae_accs_z[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import plot_hour_shift\n",
    "\n",
    "plot_hour_shift(mfcc_accs, conv_ae_accs, bae_accs, mffce_accs, vae_accs, cvae_accs_s, cvae_accs_z,\n",
    "                labels_list=['mfcc', 'conv', 'bae', 'mfcce', 'vae', 'cvae_s', 'cvae_z'],\n",
    "                xticklabels=[str(start_hour) for start_hour in start_hours],\n",
    "                save_path = 'data\\\\outputs\\\\zs_encoder_0_s.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize on 2D map, we basically perform TSNE and PCA dimension reduction in order to visualize night and day. Probably this will be not efficent but it is worth to give a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "start_hour = 23\n",
    "end_hour = 2\n",
    "\n",
    "reduce_df = pd.DataFrame(df_hive_data)\n",
    "reduce_df['feature_vector'] = StandardScaler().fit_transform(df_hive_data['bae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "reduced_ae_pca = PCA(n_components=2).fit_transform(reduce_df['feature_vector'].values.tolist())\n",
    "reduced_ae_tsne =  TSNE(n_components=2, perplexity=100, learning_rate=500).fit_transform(reduce_df['feature_vector'].values.tolist())\n",
    "is_night_list = (reduce_df.index.hour >= start_hour) | (reduce_df.index.hour <= end_hour)\n",
    "                \n",
    "colors = ['red', 'green', 'blue', 'yellow']\n",
    "labels = ['day', 'night']\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "\n",
    "axs[0].scatter(x=[data[0] for data in reduced_ae_pca],\n",
    "               y=[data[1] for data in reduced_ae_pca],\n",
    "               c=[colors[night] for night in is_night_list],\n",
    "              alpha=0.3)\n",
    "axs[0].set_title('PCA')\n",
    "\n",
    "axs[1].scatter(x=[data[0] for data in reduced_ae_tsne],\n",
    "               y=[data[1] for data in reduced_ae_tsne],\n",
    "               c=[colors[night] for night in is_night_list],\n",
    "              alpha=0.3)\n",
    "axs[1].set_title('TSNE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(reduce_df['feature_vector'].values.tolist())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def plot_distribution(distribution_dict, bin_size):\n",
    "    \"\"\" Plotting distribiution for dictionary elements\"\"\"\n",
    "    colors = ['blue', 'green', 'red', 'yellow', 'black', 'pink', 'purple']\n",
    "    rms_max = 0\n",
    "    rms_min = 65535\n",
    "    for k, v in rmses.items():\n",
    "        if np.max(v) > rms_max:\n",
    "            rms_max = np.max(v)\n",
    "        if np.min(v) < rms_min:\n",
    "            rms_min = np.min(v)\n",
    "        \n",
    "    plt.figure()\n",
    "    for idx, (k, v) in enumerate(distribution_dict.items()):\n",
    "        plt.hist(v, color=colors[idx%len(colors)], bins=int(np.abs(rms_max-rms_min)/bin_size))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of code for calculating autocorrelaction for specific feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "features = ['conv_ae', 'humidity', 'temperature',\n",
    "            'alcohol', 'aceton', 'jon-amonowy',\n",
    "            'toluen', 'co2', 'siarkowodor',\n",
    "            'metanotiol', 'trimetyloamina', 'wodor', 'co']\n",
    "\n",
    "feature = features[12]\n",
    "data_to_autocorr = df_hive_co_ua\n",
    "\n",
    "roll_len = 3\n",
    "interval = (data_to_autocorr.index[2] - data_to_autocorr.index[1]).seconds//60%60\n",
    "\n",
    "y2 = data_to_autocorr[feature].rolling(window=roll_len).mean().values\n",
    "y_corr = y2[roll_len:]\n",
    "x_corelation = np.arange(start=0, step=2, stop=150)\n",
    "\n",
    "fig, axes = plt.subplots(1, figsize=(8,5))\n",
    "x = plot_acf(y_corr, lags=x_corelation, zero=False, ax=axes)\n",
    "x_raw = acf(y_corr, nlags=150)\n",
    "axes.set_title(f'{feature} autocorrelaction')\n",
    "axes.set_xlabel(f'Lag (1 lag = {interval} minutes)') \n",
    "axes.set_ylabel('Correlation')\n",
    "axes.set_xticks(np.arange(0, 151, step=10))\n",
    "\n",
    "print(f'{feature} with max {max(x_raw[60:]):.2f} at {60 + np.argmax(x_raw[60:])}')\n",
    "\n",
    "# temperature with max 0.74 at 93 (15 mint)\n",
    "# humidity with max 0.58 at 92 (15 min)\n",
    "# alcohol with max 0.53 at 134 (10 min)\n",
    "# aceton with max 0.52 at 133 (10 min)\n",
    "# jon-amonowy with max 0.57 at 133 (10 min)\n",
    "# toluen with max 0.52 at 134 (10 min)\n",
    "# co2 with max 0.54 at 133 (10 min)\n",
    "# siarkowodor with max 0.16 at 142 (10 min)\n",
    "# metanotiol with max 0.34 at 140 (10 min)\n",
    "# trimetyloamina with max 0.56 at 138 (10 min)\n",
    "# wodor with max 0.14 at 142 (10 min)\n",
    "# co with max 0.62 at 134 (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.autoencoder_utils as ae\n",
    "import utils.data_utils as du\n",
    "import utils.customdataset as cd\n",
    "import utils.contrastive_pytorch as cp\n",
    "import utils.contrastive_keras as ck\n",
    "import utils.periodogram_dataset as pd\n",
    "\n",
    "importlib.reload(pd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}