{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "hives_ids = [\"smrpiclient7\", \"smrpiclient6\", \"smrpiclient5\"]\n",
    "# hives_ids = [\"smrpiclient7\"]\n",
    "\n",
    "# define hive under analysis\n",
    "hive_under_analysis = hives_ids[0]\n",
    "# define offset as all data should be utc\n",
    "timezone_offset_hours = 2\n",
    "# define if we should reinit our data\n",
    "DATA_INIT = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'utils.periodogram_dataset_keras' from 'c:\\\\Users\\\\tymot\\\\projects\\\\001.smartula\\\\smartula-analysis\\\\smartula-analysis\\\\notebooks\\\\utils\\\\periodogram_dataset_keras.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "import utils.periodogram_dataset as pd\n",
    "import utils.periodogram_dataset_keras as pdk\n",
    "import utils.contrastive_pytorch as cp\n",
    "import utils.contrastive_keras as ck\n",
    "import utils.data_utils as du\n",
    "import importlib\n",
    "\n",
    "importlib.reload(du)\n",
    "importlib.reload(pdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "got 39678 sound filenames read for 5 files/folders\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import create_valid_sounds_datalist, get_valid_sounds_datalist\n",
    "\n",
    "CHECK_FILES = False                             # should we perform sound checking (long)\n",
    "\n",
    "root_folder = \"..\\\\measurements\\\\smartulav2\"    # root folder with folder containing sounds\n",
    "valid_filename = \"valid-files.txt\"              # filename for file which will be contain\n",
    "                                                # filenames for valid recordings\n",
    "checked_folders = []\n",
    "if CHECK_FILES:\n",
    "    checked_folders = create_valid_sounds_datalist(root_folder, valid_filename, \"smrpiclient\")\n",
    "else:\n",
    "     checked_folders = [os.path.join(root_folder, \"smrpiclient0_10082020-19012021\"),       \n",
    "                        os.path.join(root_folder, \"smrpiclient3_10082020-19012021\"), \n",
    "                        os.path.join(root_folder, \"smrpiclient5_10082020-19012021\"),    \n",
    "                        os.path.join(root_folder, \"smrpiclient6_10082020-19012021\"),\n",
    "                        os.path.join(root_folder, \"smrpiclient7_10082020-19012021\")]\n",
    "\n",
    "sound_filenames = get_valid_sounds_datalist(checked_folders, valid_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "preparing train dataset with len: 35899...\n",
      "VAE model training performed on cuda\n",
      "-> training at epoch 1\n",
      " 28%|██▊       | 132/477 [00:12<00:32, 10.54it/s]\n",
      " 28%|██▊       | 132/477 [00:12<00:32, 10.54it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-7dd652e4b0cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=100, \\\n\u001b[1;32m---> 30\u001b[1;33m                                   dataloader_train=train_loader, dataloader_val=val_loader, checkpoint_name=PATH)\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR_OK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\tymot\\projects\\001.smartula\\smartula-analysis\\smartula-analysis\\notebooks\\utils\\contrastive_pytorch.py\u001b[0m in \u001b[0;36mtrain_vae_model\u001b[1;34m(model, learning_rate, weight_decay, num_epochs, patience, dataloader_train, dataloader_val, checkpoint_name)\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m                 \u001b[1;31m# transfer data to device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    328\u001b[0m                         _winapi.PeekNamedPipe(self._handle)[0] != 0):\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_more_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;31m# request that overlapped reads stop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\programs\\anaconda\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.periodogram_dataset import PeriodogramDataset\n",
    "from utils.contrastive_pytorch import VAE, train_vae_model\n",
    "from utils.data_utils import filter_strlist\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = 'models\\\\vae-apprirary-approach-10022021.pth'\n",
    "TRAIN = True\n",
    "\n",
    "modelVAE = VAE(encoder_layer_sizes=[2048, 512, 64], latent_size=16, decoder_layer_sizes=[64, 512, 2048]).to(device)\n",
    "\n",
    "if TRAIN:\n",
    "    # prepare train data for complete dataset\n",
    "    train_hives_soundfiles = filter_strlist(sound_filenames, \"smrpiclient5\", \"smrpiclient6\", \"smrpiclient7\")\n",
    "    print(f\"preparing train dataset with len: {len(train_hives_soundfiles)}...\")\n",
    "\n",
    "    # choose periodogram as feature\n",
    "    dataset = PeriodogramDataset(train_hives_soundfiles, train_hives, slice_freq=(0, 2048))    \n",
    "    val_amount = int(dataset.__len__() * 0.15)\n",
    "    train_set, val_set = random_split(dataset, [(dataset.__len__() - val_amount), val_amount])\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "    # train model\n",
    "    modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=100, \\\n",
    "                                  dataloader_train=train_loader, dataloader_val=val_loader, checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelVAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smrpiclient7'] vs ['smrpiclient6', 'smrpiclient5']\n",
      "['smrpiclient6'] vs ['smrpiclient7', 'smrpiclient5']\n",
      "['smrpiclient5'] vs ['smrpiclient7', 'smrpiclient6']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "from utils.periodogram_dataset_keras import PeriodogramGenerator\n",
    "from utils.contrastive_keras import contrastive_keras_vae\n",
    "from tensorflow import keras\n",
    "\n",
    "bsize = 64\n",
    "TRAIN = True\n",
    "MIXED = True\n",
    "\n",
    "# background_hives = [\"smrpiclient6\", \"smrpiclient5\"]\n",
    "# target_hives = [\"smrpiclient7\"]\n",
    "\n",
    "cvae_keras, _, _, _, sb_encoder, cvae_decoder = contrastive_keras_vae(input_dim=2048, intermediate_dim=[512, 64], latent_dim=16,\n",
    "                                                   disentangle=True, gamma=1, batch_size=bsize)\n",
    "    \n",
    "if TRAIN:        \n",
    "    for idx in range(len(hives_ids)):\n",
    "        # loop for all variants for background data\n",
    "        cvae_hives = list(hives_ids) # temporary list\n",
    "        target_hives = [cvae_hives.pop(idx)]\n",
    "        background_hives = cvae_hives\n",
    "        \n",
    "        # load target data\n",
    "        target_valid_file = [f for target_hive in target_hives for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{cvae_hives}_*\\\\valid-files.txt\")]\n",
    "        target_valid_filenames = []\n",
    "        for valid_file in target_valid_files:\n",
    "            with open(valid_file, 'r') as f:\n",
    "                target_valid_filenames += f.read().splitlines()\n",
    "    \n",
    "        # load background data\n",
    "        background_valid_files = [f for background_hive in background_hives for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{background_hive}_*\\\\valid-files.txt\")]\n",
    "        background_valid_filenames = []\n",
    "        for background_valid_file in background_valid_files:\n",
    "            with open(background_valid_file, 'r') as f:\n",
    "                background_valid_filenames += f.read().splitlines()\n",
    "        background_valid_filenames = background_valid_filenames[:len(target_valid_filenames)]\n",
    "        \n",
    "        # Prepare dataset and train\n",
    "        train_generator = PeriodogramGenerator(target_valid_filenames, background_valid_filenames,\n",
    "                                               batch_size=bsize, labels=[target_hive], slice_freq=(0, 2048))\n",
    "        history = cvae_keras.fit(train_generator, epochs=10, batch_size=bsize, verbose=1)\n",
    "    \n",
    "        cvae_keras.save_weights('models/cvae_keras_weights_10022021.h5')\n",
    "        sb_encoder.save_weights('models/sb_encoder_weights_10022021.h5')\n",
    "        cvae_decoder.save_weights('models/cvae_decoder_weights_10022021.h5')\n",
    "else:\n",
    "    cvae_keras.load_weights('models/cvae_keras_weights_10022021.h5')\n",
    "    sb_encoder.load_weights('models/sb_encoder_weights_10022021.h5')\n",
    "    cvae_decoder.load_weights('models/cvae_decoder_weights_10022021.h5')\n",
    "    print(f'model loaded successfully')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:08<00:00, 298.56it/s]\n",
      "  2%|▏         | 46/2452 [00:00<00:10, 226.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:08<00:00, 274.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss vs train loss : 0.005118480417877436 : 0.0038946554996073246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils.periodogram_dataset import PeriodogramDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data_utils import normal_pdf\n",
    "\n",
    "hives_ids_test = [\"smrpiclient3\"]\n",
    "hut_sounds_files = [f for hive_name_test in hives_ids_test for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name_test}_*\\\\*.wav\")]\n",
    "all_sound_files = [f for hive_name in hives_ids for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_name}_*\\\\*.wav\")]\n",
    "\n",
    "# pytorch\n",
    "hut_dataset = PeriodogramDataset(hut_sounds_files, hives_ids_test, slice_freq=(0, 2048))\n",
    "all_sound_dataset = PeriodogramDataset(all_sound_files, hives_ids, slice_freq=(0, 2048))\n",
    "\n",
    "# get indices for all_sound_dataset\n",
    "subset_indices = np.random.randint(0, len(all_sound_dataset), len(hut_dataset))\n",
    "dataset = torch.utils.data.Subset(all_sound_dataset, subset_indices)\n",
    "\n",
    "test_loss = []\n",
    "train_loss = []\n",
    "with torch.no_grad():\n",
    "    modelVAE.eval()\n",
    "    print(f'validating on test set', flush=True)\n",
    "    for input_data in tqdm(hut_dataset, position=0, leave=True):\n",
    "        if input_data:\n",
    "            input_data = torch.Tensor(input_data[0]).to(device)\n",
    "            output, mean, var = modelVAE(input_data.to(device))\n",
    "            test_loss.append(F.mse_loss(output, input_data).cpu().numpy())\n",
    "            \n",
    "    print(f'validating on training set')\n",
    "    for input_data in tqdm(dataset, position=0, leave=True):\n",
    "        if input_data:\n",
    "            input_data = torch.Tensor(input_data[0]).to(device)\n",
    "            output, _, _ = modelVAE(input_data.to(device))\n",
    "            train_loss.append(F.mse_loss(output, input_data).cpu().numpy())\n",
    "                \n",
    "test_loss_avg = np.mean(test_loss)\n",
    "train_loss_avg = np.mean(train_loss)\n",
    "                                       \n",
    "print(f'test loss vs train loss : {test_loss_avg} : {train_loss_avg}')\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:03<00:00, 797.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss for hive under test: 0.004782302770763636\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from operator import itemgetter \n",
    "from utils.periodogram_dataset_keras import PeriodogramGenerator, read_sound_file\n",
    "from tqdm import tqdm \n",
    "\n",
    "hut_sounds =  np.array([read_sound_file(f, (0, 2048)) for f in tqdm(hut_sounds_files)])\n",
    "mean, var, latent = sb_encoder.predict(hut_sounds)\n",
    "zeros = np.zeros_like(latent)\n",
    "decoder_input = np.concatenate((zeros, latent), axis=1)\n",
    "cvae_output = cvae_decoder.predict(decoder_input)\n",
    "loss = tf.keras.losses.mean_squared_error(hut_sounds, cvae_output)\n",
    "\n",
    "print(f'MSE loss for hive under test: {np.mean(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2452/2452 [00:03<00:00, 695.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss for background test: 0.0020129058975726366\n"
     ]
    }
   ],
   "source": [
    "subset_indices = np.random.randint(0, len(background_valid_filenames), len(hut_sounds))\n",
    "\n",
    "background_train_sound_files = list(itemgetter(*subset_indices)(background_valid_filenames))\n",
    "bg_sounds = np.array([read_sound_file(f, (0, 2048)) for f in tqdm(background_train_sound_files)])\n",
    "mean, var, latent = sb_encoder.predict(bg_sounds)\n",
    "zeros = np.zeros_like(latent)\n",
    "decoder_input = np.concatenate((zeros, latent), axis=1)\n",
    "cvae_output = cvae_decoder.predict(decoder_input)\n",
    "loss = tf.keras.losses.mean_squared_error(bg_sounds, cvae_output)\n",
    "\n",
    "print(f'MSE loss for background test: {np.mean(loss)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Here we load train data sound samples and prepare spectrogram, periodogram and mfcc features (along with some data to visualize this). We should provide data with **utc timestamps** as it will be shifted with `timezone_offset_hours` var. What we also do is remove those samples which has strange rms signal. Threshold 0.8 was chosen based on `plot_distribution` output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "sound_time_ms = 2000\n",
    "# ~93 ms for fft window\n",
    "nfft = 4096\n",
    "# ~34% overlapping\n",
    "hop_len = (nfft//3) + 30\n",
    "# This can be manipulated to adjust number of bins for conv layer\n",
    "fmax = 2750\n",
    "\n",
    "hives_data = []\n",
    "rmses = {}\n",
    "max_to_norm = 0\n",
    "\n",
    "if DATA_INIT:\n",
    "    for idx, hive_id in enumerate(hives_ids):\n",
    "        sound_files = [f for f in glob.glob(f\"..\\\\measurements\\\\smartulav2\\\\{hive_id}_*\\\\*.wav\")]\n",
    "        print(f\"Sound data preparation for hive: {hive_id} which has {len(sound_files)} recordings...\", end=' ', flush=True)\n",
    "        for file in tqdm(sound_files):\n",
    "            sample_rate, sound_samples = wavfile.read(file)\n",
    "            sound_samples = sound_samples.T[0]/(2.0**31)\n",
    "            rms = np.sqrt(sum(sound_samples**2)/len(sound_samples))\n",
    "            if rms < 0.7:    # that threshold was observed from plot_distribution() function\n",
    "                # calculate timestamp\n",
    "                filename = file.rsplit('\\\\', 1)[-1]\n",
    "                utc_timestamp = filename[filename.index('-')+1:].rsplit(\".wav\")[0]\n",
    "                sound_datetime = datetime.strptime(utc_timestamp, '%Y-%m-%dT%H-%M-%S') + timedelta(hours=timezone_offset_hours)\n",
    "                \n",
    "                # calculate mfcc feature\n",
    "                mfccs = librosa.feature.mfcc(y=sound_samples, sr=sample_rate, n_fft=nfft, hop_length=hop_len, n_mfcc=13)\n",
    "                np_mfcc_avg = np.mean(mfccs, axis=1)\n",
    "                \n",
    "                # calculate spectrogram\n",
    "                spectrogram = librosa.core.stft(sound_samples, n_fft=nfft, hop_length=hop_len)\n",
    "                spectrogram_magnitude = np.abs(spectrogram)\n",
    "                spectrogram_phase = np.angle(spectrogram)\n",
    "                spectrogram_db = librosa.amplitude_to_db(spectrogram_magnitude, ref=np.max)\n",
    "                frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=nfft)\n",
    "                times = (np.arange(0, spectrogram_magnitude.shape[1])*hop_len)/sample_rate\n",
    "                freq_slice = np.where((frequencies < fmax))\n",
    "                frequencies = frequencies[freq_slice]\n",
    "                spectrogram_db = spectrogram_db[freq_slice, :][0]\n",
    "                spectrogram_mean = np.mean(spectrogram_db, axis=1)\n",
    "                # decimate?\n",
    "                # spectrogram_db_decimated = decimate(spectrogram_db.T, 4).T\n",
    "                # frequencies_decimated = decimate(frequencies, 4)\n",
    "\n",
    "                #calculate periodogram\n",
    "                periodogram = fft(sound_samples, n=sample_rate)\n",
    "                periodogram = abs(periodogram[1:int(len(periodogram)/2)])\n",
    "                periodogram_freq = fftfreq(len(sound_samples)//(sound_time_ms//1000), 1/sample_rate)\n",
    "                periodogram_freq = periodogram_freq[:(len(periodogram_freq)//2)-1]\n",
    "                \n",
    "                hives_data.append(\n",
    "                    {\n",
    "                        'datetime': sound_datetime,\n",
    "                        'id': hive_id,\n",
    "                        'samples': sound_samples,\n",
    "                        'freq':\n",
    "                            {\n",
    "                                'spectrogram':\n",
    "                                    {\n",
    "                                        'frequencies': frequencies,\n",
    "                                        'time': times,\n",
    "                                        'spectrogram_full_db': spectrogram_db,\n",
    "                                        'spectrogram_mean': spectrogram_mean\n",
    "                                    },\n",
    "                                'periodogram':\n",
    "                                    {\n",
    "                                        'frequencies': periodogram_freq,\n",
    "                                        'samples': periodogram\n",
    "                                    }\n",
    "                            },\n",
    "                        'features':\n",
    "                            {\n",
    "                                'mfcc_avg': np_mfcc_avg\n",
    "                            }\n",
    "                    }\n",
    "                )\n",
    "        print(\" done.\")\n",
    "        \n",
    "    print(\"saving data on disc...\", end=' ')\n",
    "    np.save('data/raw_hives_data.npy', hives_data, allow_pickle=True)\n",
    "    print(\"done.\")\n",
    "else:\n",
    "    hives_data = np.load('data/raw_hives_data.npy', allow_pickle=True)\n",
    "    \n",
    "print(f\"got full dataset of {len(hives_data)} sound samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data preprocessing \n",
    "\n",
    "Here we perform scaling standarization etc.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "sc = StandardScaler()\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "# extract every spectrogram from hives data list and standarize every periodogram from stft \n",
    "# so data for spectrogram will have zero mean and unit variance + scale every standarized periodogram\n",
    "print('preparing spectrograms...', end=' ', flush=True)\n",
    "spectrograms = [hive_data['freq']['spectrogram']['spectrogram_full_db'] for hive_data in hives_data]\n",
    "# standarized_spectrograms = [sc.fit_transform(spectrogram.T).T for spectrogram in tqdm(spectrograms)]\n",
    "scaled_spectrogram = [mm.fit_transform(spectrogram.T).T for spectrogram in tqdm(spectrograms, position=0, leave=True)]\n",
    "print('done.')\n",
    "\n",
    "# get datatime, names and mfcc\n",
    "print('getting mfccs', end=' ')\n",
    "datetimes = [hive_data['datetime'] for hive_data in hives_data]\n",
    "names = [hive_data['id'] for hive_data in hives_data]\n",
    "mfccs = [hive_data['features']['mfcc_avg'] for hive_data in hives_data]\n",
    "print('done.')\n",
    "\n",
    "# standarize and scale mean spectrogram for sounds\n",
    "print('preparing spectrogram means', end=' ')\n",
    "spectrograms_mean = [hive_data['freq']['spectrogram']['spectrogram_mean'] for hive_data in hives_data]\n",
    "standarized_spectrograms_mean = StandardScaler().fit_transform(spectrograms_mean)\n",
    "scaled_spectrograms_means = MinMaxScaler().fit_transform(standarized_spectrograms_mean)\n",
    "print('done.')\n",
    "\n",
    "# prepare truncated periodogram\n",
    "end_frequency = 2048\n",
    "print(f'preparing truncated periodograms ({end_frequency})', end=' ', flush=True)\n",
    "periodograms = [hive_data['freq']['periodogram']['samples'][:end_frequency] for hive_data in hives_data]\n",
    "periodograms = [mm.fit_transform(perio.reshape(-1, 1)).T for perio in tqdm(periodograms, position=0, leave=True)]\n",
    "print('done.')\n",
    "\n",
    "sounds = list(zip(scaled_spectrogram, mfccs, scaled_spectrograms_means, periodograms, datetimes, names))\n",
    "\n",
    "sounds_data = pd.DataFrame(sounds, columns=['spectrogram', 'mfccs', 'spectrogram_mean', 'periodogram', 'datetime', 'name'])\n",
    "sounds_data['datetime'] = pd.to_datetime(sounds_data['datetime'])\n",
    "sounds_hive_data = sounds_data[sounds_data['name'] == hive_under_analysis]\n",
    "\n",
    "print(f\"Got dataset of size: {len(sounds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CONTRASTIVE AE - keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounds_data[sounds_data['name'] == 'smrpiclient7']['periodogram'].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.contrastive_keras import contrastive_keras_vae\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "target_keras = np.stack(sounds_data[sounds_data['name'] == 'smrpiclient7']['periodogram'].to_numpy()[:3000]).squeeze()\n",
    "background_keras = np.stack(sounds_data[sounds_data['name'] == 'smrpiclient6']['periodogram'].to_numpy()[:3000]).squeeze()\n",
    "\n",
    "print(f'training cvae (keras) with target of shape: {target_keras.shape} '\n",
    "    f'and background of shape: {background_keras.shape}')\n",
    "\n",
    "assert(target_keras.shape == background_keras.shape)\n",
    "\n",
    "cvae_keras, cvae_fg, z_encoder_keras, s_encoder_keras, cvae_keras_decoder = contrastive_keras_vae(\n",
    "    input_dim=2048, intermediate_dim=512, latent_dim=16, disentangle=True, gamma=1)\n",
    "history = cvae_keras.fit([target_keras, background_keras], epochs=50, batch_size=100, \n",
    "                         validation_data=([target_keras, background_keras], None), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train BASIC AE\n",
    "Here we train basic fully connected autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "\n",
    "from torch.utils import data as tdata\n",
    "from utils.data_utils import prepare_dataset1d\n",
    "from utils.autoencoder_utils import BasicAutoencoder, train_model\n",
    "\n",
    "TRAIN_MODEL = False\n",
    "PATH = 'basic_ae.pth'\n",
    "\n",
    "modelBasicAE = BasicAutoencoder().to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    train_dataloader, val_dataloader = prepare_dataset1d(sounds_hive_data['spectrogram_mean'], train_ratio=0.8, batch_size=64)\n",
    "    modelBasicAE = train_model(modelBasicAE,\n",
    "                           learning_rate=1e-3, weight_decay=1e-5, num_epochs=10, patience=20,\n",
    "                           dataloader_train=train_dataloader, dataloader_val=val_dataloader,\n",
    "                           checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelBasicAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CONV AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we train convolutional autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import data as tdata\n",
    "from utils.data_utils import prepare_dataset2d\n",
    "from utils.autoencoder_utils import ConvAutoencoder, train_model\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "PATH = 'conv_ae.pth'\n",
    "\n",
    "modelConvAE = ConvAutoencoder().to(device)\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    train_set, val_set = prepare_dataset2d(sounds_hive_data['spectrogram'], train_ratio=0.8)\n",
    "    \n",
    "    dataloader_train = tdata.DataLoader(train_set, batch_size=6, shuffle=True)\n",
    "    dataloader_val = tdata.DataLoader(val_set, batch_size=6, shuffle=True)\n",
    "    \n",
    "    modelConvAE = train_model(modelConvAE,\n",
    "                               learning_rate=1e-3, weight_decay=1e-6, num_epochs=100, patience=20,\n",
    "                               dataloader_train=dataloader_train, dataloader_val=dataloader_val,\n",
    "                               checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelConvAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no such file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train vae autoencoder on data from particular hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils import data as tdata\n",
    "from torchvision import transforms\n",
    "from utils.data_utils import prepare_dataset1d\n",
    "from utils.contrastive_pytorch import VAE, train_vae_model\n",
    "from utils.customdataset import CustomDataset\n",
    "\n",
    "TRAIN_MODEL = True\n",
    "PATH = 'vae.pth'\n",
    "\n",
    "modelVAE = VAE(encoder_layer_sizes=[2048, 512, 64], latent_size=16, decoder_layer_sizes=[64, 512, 2048])\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    data = torch.Tensor(sounds_hive_data['periodogram'])\n",
    "    data = data[:, None, :]\n",
    "    idx_split = data.size(0)*80//100\n",
    "    train_dataset = CustomDataset(data[:idx_split], should_scale=True)\n",
    "    val_dataset = CustomDataset(data[idx_split:], should_scale=True)\n",
    "    train_dataloader = tdata.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_dataloader = tdata.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    modelVAE = train_vae_model(modelVAE, learning_rate=1e-3, weight_decay=1e-5, num_epochs=100, patience=100,\n",
    "                              dataloader_train=train_dataloader, dataloader_val=val_dataloader, checkpoint_name=PATH)\n",
    "else:\n",
    "    if os.path.isfile(PATH) and os.access(PATH, os.R_OK):\n",
    "        modelVAE.load_state_dict(torch.load(PATH))\n",
    "        print('model load success!')\n",
    "    else:\n",
    "        print(f'ERROR! There is no such file: {PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# read just sample file as probably all has the same sampling rate\n",
    "sample_rate, samples = wavfile.read('C:\\\\Users\\\\tymot\\\\projects\\\\001.smartula\\\\smartula-analysis\\\\smartula-analysis'\n",
    "                           '\\\\measurements\\\\smartulav2\\\\smrpiclient6_10082020-15092020\\\\DEADBEEF94-2020-08-10T03-11-50.wav')\n",
    "idx = random.randint(0, sounds_hive_data.shape[0] - 1)\n",
    "idx = 2240\n",
    "with torch.no_grad():   \n",
    "    modelConvAE.eval()\n",
    "    modelBasicAE.eval()\n",
    "    modelVAE.eval()\n",
    "    \n",
    "    # Get sound from sounds hive data (with respect to hive under analysis)\n",
    "    sound = sounds_hive_data.iloc[idx]\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "    fig.suptitle(f'Convolutional Autoencoder real vs output for sample id: {idx}')\n",
    "    fig.tight_layout(pad = 3.0)\n",
    "\n",
    "    frequencies = librosa.fft_frequencies(sr=sample_rate, n_fft=nfft)\n",
    "    freq_slice = np.where((frequencies < fmax))\n",
    "    frequencies = frequencies[freq_slice]\n",
    "    times = (np.arange(0, sound['spectrogram'].shape[1])*hop_len)/sample_rate\n",
    "    elem = sound['spectrogram']\n",
    "    elem = elem[None, None, :, :]\n",
    "    elem = torch.Tensor(elem).to(device)\n",
    "    \n",
    "    elem_mean = sound['spectrogram_mean']\n",
    "    elem_mean = elem_mean[None, :]\n",
    "    elem_mean = torch.Tensor(elem_mean).to(device)\n",
    "    \n",
    "    axs[0][0].set_title('real spectrogram')\n",
    "    axs[0][0].pcolormesh(times, frequencies, sound['spectrogram'])\n",
    "    axs[0][1].set_title('encoded conv2d')\n",
    "    axs[0][1].pcolormesh(times, frequencies, modelConvAE(elem.to(device)).cpu().numpy().squeeze())\n",
    "    \n",
    "    # prepare data for vae prediction\n",
    "    freqs = np.arange(sound['periodogram'].shape[1])\n",
    "    input_data = torch.Tensor(sound['periodogram']).to(device)\n",
    "    vae_output, _, _ = modelVAE(input_data)\n",
    "    \n",
    "    # prepare data for cvae prediction\n",
    "    s_mean, s_log_var, s = s_encoder_keras.predict(sound['periodogram'])\n",
    "    latent = np.concatenate((np.zeros_like(s), s), axis = 1)\n",
    "    cvae_output = cvae_keras_decoder.predict(latent)\n",
    "\n",
    "    axs[1][0].set_title('spectrogram mean')\n",
    "    axs[1][0].plot(sound['spectrogram_mean'], label='real', color='blue')\n",
    "    axs[1][0].plot(modelBasicAE(elem_mean).cpu().numpy().squeeze(), label='encoded', color='red')\n",
    "    axs[1][0].legend()\n",
    "    \n",
    "    axs[1][1].set_title('periodogram')\n",
    "    axs[1][1].plot(freqs, periodogram_df, label='real', color='blue')\n",
    "    axs[1][1].plot(freqs, vae_output.cpu().numpy().squeeze(), label='vae encoded', color='red')\n",
    "    axs[1][1].plot(freqs, cvae_output.squeeze(), label='cvae encoded', color='green')\n",
    "    axs[1][1].legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add temperature/humidity/gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import read_sensor_data\n",
    "\n",
    "start_time = '2020-08-10 00:00:00'\n",
    "end_time = '2020-09-16 00:00:00'\n",
    "print(f\"extracting data for hive under analysis: {hive_under_analysis} from {start_time} to {end_time}...\")\n",
    "\n",
    "df_hives_sound = pd.DataFrame(sounds_data)\n",
    "df_hive_sound_ua = df_hives_sound[(df_hives_sound['name'] == hive_under_analysis)\n",
    "                                 & (df_hives_sound['datetime'] > start_time)\n",
    "                                 & (df_hives_sound['datetime'] < end_time)]\n",
    "df_hive_sound_ua.set_index('datetime', inplace=True)\n",
    "print(f\"-> prepared base of {df_hive_sound_ua.count()['spectrogram']} number of sound spectrums <-\")\n",
    "\n",
    "df_hive_temperature_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-temperature.csv',\n",
    "                                          hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'temperature')\n",
    "df_hive_humidity_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-humidity.csv',\n",
    "                                       hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'humidity')\n",
    "df_hive_alcohol_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-alcohol.csv',\n",
    "                                      hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'alcohol')\n",
    "df_hive_aceton_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-aceton.csv',\n",
    "                                     hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'aceton')\n",
    "df_hive_amon_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-jon-amonowy.csv',\n",
    "                                   hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'jon-amonowy')\n",
    "df_hive_toluen_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-toluen.csv',\n",
    "                                     hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'toluen')\n",
    "df_hive_co2_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-co2.csv',\n",
    "                                    hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'co2')\n",
    "df_hive_siarkowodor_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-siarkowodor.csv',\n",
    "                                          hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'siarkowodor')\n",
    "df_hive_metanotiol_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-metanotiol.csv',\n",
    "                                         hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'metanotiol')\n",
    "df_hive_trimetyloamina_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-trimetyloamina.csv',\n",
    "                                         hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'trimetyloamina')\n",
    "df_hive_wodor_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-wodor.csv',\n",
    "                                    hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'wodor')\n",
    "df_hive_co_ua = read_sensor_data('..//measurements//smartulav2//sulmin-10082020-15092020-inside-co.csv',\n",
    "                                 hive_under_analysis, hives_ids, start_time, end_time, timezone_offset_hours, 'co')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check autocorrelation for specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import merge_dataframes_ontimestamp, merge_columns\n",
    "from utils.autoencoder_utils import conv2d_encode, basic_ae_encode\n",
    "from utils.contrastive_pytorch import vae_encode\n",
    "from utils.contrastive_keras import cvae_encode\n",
    "\n",
    "df_hive_data = merge_dataframes_ontimestamp(df_hive_sound_ua,\n",
    "                                            df_hive_temperature_ua, df_hive_humidity_ua,\n",
    "                                            df_hive_alcohol_ua, df_hive_aceton_ua, df_hive_amon_ua, df_hive_toluen_ua, df_hive_co2_ua,\n",
    "                                            df_hive_siarkowodor_ua, df_hive_metanotiol_ua, df_hive_trimetyloamina_ua, df_hive_wodor_ua,\n",
    "                                            df_hive_co_ua)\n",
    "\n",
    "df_hive_data['conv_ae'] = conv2d_encode(modelConvAE, df_hive_data['spectrogram'].to_list())\n",
    "df_hive_data['basic_ae'] = basic_ae_encode(modelBasicAE, df_hive_data['spectrogram_mean'].to_list())\n",
    "df_hive_data['vae'] = vae_encode(modelVAE, df_hive_data['periodogram'].to_list()).tolist()\n",
    "df_hive_data['cvae_s'] = cvae_encode(s_encoder_keras, df_hive_data['periodogram']).tolist()\n",
    "df_hive_data['cvae_z'] = cvae_encode(z_encoder_keras, df_hive_data['periodogram']).tolist()\n",
    "\n",
    "df_hive_data['bae_feature_vector'] = merge_columns(df_hive_data, ['basic_ae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['conv_feature_vector'] = merge_columns(df_hive_data, ['conv_ae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['mfcc_feature_vector'] = merge_columns(df_hive_data, ['mfccs', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['vae_feature_vector'] = merge_columns(df_hive_data, ['vae', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['cvae_s_feature_vector'] = merge_columns(df_hive_data, ['cvae_s', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])\n",
    "df_hive_data['cvae_z_feature_vector'] = merge_columns(df_hive_data, ['cvae_z', 'humidity', 'temperature', \n",
    "                                                                  'alcohol', 'aceton', 'jon-amonowy', 'toluen', 'co2', 'trimetyloamina', 'co'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.data_utils import search_best_night_day\n",
    "\n",
    "start_hours = [20, 21, 22, 23, 0, 1, 2, 3, 4]\n",
    "\n",
    "df_hive_data_scaled = pd.DataFrame(df_hive_data)\n",
    "\n",
    "# data for convolutional autoencoder\n",
    "df_hive_data_scaled['conv_feature_vector'] = StandardScaler().fit_transform(df_hive_data['conv_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for basic autoencoder\n",
    "df_hive_data_scaled['bae_feature_vector'] = StandardScaler().fit_transform(df_hive_data['bae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for mfcc features\n",
    "df_hive_data_scaled['mfcc_feature_vector'] = StandardScaler().fit_transform(df_hive_data['mfcc_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for vae features\n",
    "df_hive_data_scaled['vae_feature_vector'] = StandardScaler().fit_transform(df_hive_data['vae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for cvae s features\n",
    "df_hive_data_scaled['cvae_s_feature_vector'] = StandardScaler().fit_transform(df_hive_data['cvae_s_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for cvae s features\n",
    "df_hive_data_scaled['cvae_z_feature_vector'] = StandardScaler().fit_transform(df_hive_data['cvae_z_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "# data for plain mfcc \n",
    "mfccs = [hive_data['features']['mfcc_avg'] for hive_data in hives_data if hive_data['id'] == hive_under_analysis]\n",
    "mfccs = StandardScaler().fit_transform(mfccs)\n",
    "datetimes = [hive_data['datetime'] for hive_data in hives_data if hive_data['id'] == hive_under_analysis]\n",
    "mfccs_data = list(zip(datetimes, mfccs))\n",
    "pd_mfcc_data = pd.DataFrame(mfccs_data, columns=['datetime', 'mfcc'])\n",
    "pd_mfcc_data.set_index('datetime', inplace=True)\n",
    "\n",
    "# calculate one class SVM match\n",
    "print('calculating mfccs match...', end=' ', flush=True)\n",
    "mfcc_accs = search_best_night_day(pd_mfcc_data, 'mfcc', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(mfcc_accs)}/{len(mfcc_accs[0])}')\n",
    "print('calculating conv ae feature vector match...', end=' ', flush=True)\n",
    "conv_ae_accs = search_best_night_day(df_hive_data_scaled, 'conv_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(conv_ae_accs)}/{len(conv_ae_accs[0])}')\n",
    "print('calculating basic ae feature vector match...', end=' ', flush=True)\n",
    "bae_accs = search_best_night_day(df_hive_data_scaled, 'bae_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(bae_accs)}/{len(bae_accs[0])}')\n",
    "print('calculating mfccs extended feature vector match...', end=' ', flush=True)\n",
    "mffce_accs = search_best_night_day(df_hive_data_scaled, 'mfcc_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(mffce_accs)}/{len(mffce_accs[0])}')\n",
    "print('calculating vae feature vector match...', end=' ', flush=True)\n",
    "vae_accs = search_best_night_day(df_hive_data_scaled, 'vae_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(vae_accs)}/{len(vae_accs[0])}')\n",
    "print('calculating cvae s feature vector match...', end=' ', flush=True)\n",
    "cvae_accs_s = search_best_night_day(df_hive_data_scaled, 'cvae_s_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(cvae_accs_s)}/{len(cvae_accs_s[0])}')\n",
    "print('calculating cvae z feature vector match...', end=' ', flush=True)\n",
    "cvae_accs_z = search_best_night_day(df_hive_data_scaled, 'cvae_z_feature_vector', days_as_test=10, start_hours=start_hours, max_shift=6, verbose=0)\n",
    "print(f'done. {len(cvae_accs_z)}/{len(cvae_accs_z[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import plot_hour_shift\n",
    "\n",
    "plot_hour_shift(mfcc_accs, conv_ae_accs, bae_accs, mffce_accs, vae_accs, cvae_accs_s, cvae_accs_z,\n",
    "                labels_list=['mfcc', 'conv', 'bae', 'mfcce', 'vae', 'cvae_s', 'cvae_z'],\n",
    "                xticklabels=[str(start_hour) for start_hour in start_hours],\n",
    "                save_path = 'data\\\\outputs\\\\zs_encoder_0_s.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize on 2D map, we basically perform TSNE and PCA dimension reduction in order to visualize night and day. Probably this will be not efficent but it is worth to give a shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "start_hour = 23\n",
    "end_hour = 2\n",
    "\n",
    "reduce_df = pd.DataFrame(df_hive_data)\n",
    "reduce_df['feature_vector'] = StandardScaler().fit_transform(df_hive_data['bae_feature_vector'].values.tolist()).tolist()\n",
    "\n",
    "reduced_ae_pca = PCA(n_components=2).fit_transform(reduce_df['feature_vector'].values.tolist())\n",
    "reduced_ae_tsne =  TSNE(n_components=2, perplexity=100, learning_rate=500).fit_transform(reduce_df['feature_vector'].values.tolist())\n",
    "is_night_list = (reduce_df.index.hour >= start_hour) | (reduce_df.index.hour <= end_hour)\n",
    "                \n",
    "colors = ['red', 'green', 'blue', 'yellow']\n",
    "labels = ['day', 'night']\n",
    "\n",
    "fig, axs = plt.subplots(2, figsize=(10,10))\n",
    "\n",
    "axs[0].scatter(x=[data[0] for data in reduced_ae_pca],\n",
    "               y=[data[1] for data in reduced_ae_pca],\n",
    "               c=[colors[night] for night in is_night_list],\n",
    "              alpha=0.3)\n",
    "axs[0].set_title('PCA')\n",
    "\n",
    "axs[1].scatter(x=[data[0] for data in reduced_ae_tsne],\n",
    "               y=[data[1] for data in reduced_ae_tsne],\n",
    "               c=[colors[night] for night in is_night_list],\n",
    "              alpha=0.3)\n",
    "axs[1].set_title('TSNE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(reduce_df['feature_vector'].values.tolist())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def plot_distribution(distribution_dict, bin_size):\n",
    "    \"\"\" Plotting distribiution for dictionary elements\"\"\"\n",
    "    colors = ['blue', 'green', 'red', 'yellow', 'black', 'pink', 'purple']\n",
    "    rms_max = 0\n",
    "    rms_min = 65535\n",
    "    for k, v in rmses.items():\n",
    "        if np.max(v) > rms_max:\n",
    "            rms_max = np.max(v)\n",
    "        if np.min(v) < rms_min:\n",
    "            rms_min = np.min(v)\n",
    "        \n",
    "    plt.figure()\n",
    "    for idx, (k, v) in enumerate(distribution_dict.items()):\n",
    "        plt.hist(v, color=colors[idx%len(colors)], bins=int(np.abs(rms_max-rms_min)/bin_size))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of code for calculating autocorrelaction for specific feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "features = ['conv_ae', 'humidity', 'temperature',\n",
    "            'alcohol', 'aceton', 'jon-amonowy',\n",
    "            'toluen', 'co2', 'siarkowodor',\n",
    "            'metanotiol', 'trimetyloamina', 'wodor', 'co']\n",
    "\n",
    "feature = features[12]\n",
    "data_to_autocorr = df_hive_co_ua\n",
    "\n",
    "roll_len = 3\n",
    "interval = (data_to_autocorr.index[2] - data_to_autocorr.index[1]).seconds//60%60\n",
    "\n",
    "y2 = data_to_autocorr[feature].rolling(window=roll_len).mean().values\n",
    "y_corr = y2[roll_len:]\n",
    "x_corelation = np.arange(start=0, step=2, stop=150)\n",
    "\n",
    "fig, axes = plt.subplots(1, figsize=(8,5))\n",
    "x = plot_acf(y_corr, lags=x_corelation, zero=False, ax=axes)\n",
    "x_raw = acf(y_corr, nlags=150)\n",
    "axes.set_title(f'{feature} autocorrelaction')\n",
    "axes.set_xlabel(f'Lag (1 lag = {interval} minutes)') \n",
    "axes.set_ylabel('Correlation')\n",
    "axes.set_xticks(np.arange(0, 151, step=10))\n",
    "\n",
    "print(f'{feature} with max {max(x_raw[60:]):.2f} at {60 + np.argmax(x_raw[60:])}')\n",
    "\n",
    "# temperature with max 0.74 at 93 (15 mint)\n",
    "# humidity with max 0.58 at 92 (15 min)\n",
    "# alcohol with max 0.53 at 134 (10 min)\n",
    "# aceton with max 0.52 at 133 (10 min)\n",
    "# jon-amonowy with max 0.57 at 133 (10 min)\n",
    "# toluen with max 0.52 at 134 (10 min)\n",
    "# co2 with max 0.54 at 133 (10 min)\n",
    "# siarkowodor with max 0.16 at 142 (10 min)\n",
    "# metanotiol with max 0.34 at 140 (10 min)\n",
    "# trimetyloamina with max 0.56 at 138 (10 min)\n",
    "# wodor with max 0.14 at 142 (10 min)\n",
    "# co with max 0.62 at 134 (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils.autoencoder_utils as ae\n",
    "import utils.data_utils as du\n",
    "import utils.customdataset as cd\n",
    "import utils.contrastive_pytorch as cp\n",
    "import utils.contrastive_keras as ck\n",
    "import utils.periodogram_dataset as pd\n",
    "\n",
    "importlib.reload(pd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}